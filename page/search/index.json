[{"content":"","href":"/scala/intro/","title":"Intro"},{"content":"","href":"/scala/","title":"Scalas"},{"content":"","href":"/java/intro/","title":"Intro"},{"content":"","href":"/java/","title":"Javas"},{"content":"","href":"/flink/","title":"Flinks"},{"content":" haha ","href":"/flink/intro/","title":"Intro"},{"content":"","href":"/kafka/","title":"Kafkas"},{"content":" Kafka 源码解析之 broker启动  基于 kafka 2.3.0 C:/kafka created on 0327 modified on 0410 学习了 scala 之后我又来了\n  Kafka 启动脚本分析 Kafka 核心主类 kafka.Kafka 由于作者的 java 知识相对薄弱，源码注解可能做的比较细\nobject Kafka extends Logging { // 读取配置文件方法  def getPropsFromArgs(args: Array[String]): Properties = { // 处理命令行参数的解析工具 OptionParser  val optionParser = new OptionParser(false) // 允许覆盖内容  val overrideOpt = optionParser.accepts(\u0026#34;override\u0026#34;, \u0026#34;Optional property that should override values set in server.properties file\u0026#34;) .withRequiredArg() .ofType(classOf[String]) // This is just to make the parameter show up in the help output, we are not actually using this due the  // fact that this class ignores the first parameter which is interpreted as positional and mandatory  // but would not be mandatory if --version is specified  // This is a bit of an ugly crutch till we get a chance to rework the entire command line parsing  val versionOpt = optionParser.accepts(\u0026#34;version\u0026#34;, \u0026#34;Print version information and exit.\u0026#34;) // 如果 命令行参数 为 0  if (args.length == 0 || args.contains(\u0026#34;--help\u0026#34;)) { CommandLineUtils.printUsageAndDie(optionParser, \u0026#34;USAGE: java [options] %s server.properties [--override property=value]*\u0026#34;.format(classOf[KafkaServer].getSimpleName())) } if (args.contains(\u0026#34;--version\u0026#34;)) { CommandLineUtils.printVersionAndDie() } val props = Utils.loadProps(args(0)) if (args.length \u0026gt; 1) { val options = optionParser.parse(args.slice(1, args.length): _*) if (options.nonOptionArguments().size() \u0026gt; 0) { CommandLineUtils.printUsageAndDie(optionParser, \u0026#34;Found non argument parameters: \u0026#34; + options.nonOptionArguments().toArray.mkString(\u0026#34;,\u0026#34;)) } props ++= CommandLineUtils.parseKeyValueArgs(options.valuesOf(overrideOpt).asScala) } props } // Kafka 实际的执行类  def main(args: Array[String]): Unit = { try { //上述的 getPropsFromArgs 获取配置文件信息  val serverProps = getPropsFromArgs(args) // 调用了KafkaServerStartable 对象 读取 props 文件，里面实际上是调用了 KafkaServer.startup()  val kafkaServerStartable = KafkaServerStartable.fromProps(serverProps) // 操作系统判断  try { if (!OperatingSystem.IS_WINDOWS \u0026amp;\u0026amp; !Java.isIbmJdk) new LoggingSignalHandler().register() } catch { case e: ReflectiveOperationException =\u0026gt; warn(\u0026#34;Failed to register optional signal handler that logs a message when the process is terminated \u0026#34; + s\u0026#34;by a signal. Reason for registration failure is: $e\u0026#34;, e) } // attach shutdown handler to catch terminating signals as well as normal termination  // Runtime 用了单实例的设计模式，所以在java程序中不同线程通过调用Runtime.getRuntime()获得的是同一个对象实例，  // 也就是说一个java进程中只有一个Runtime实例  //该函数的作用就是在你的程序结束前,执行一些清理工作,尤其是没有用户界面的程序.很明显,这些关闭钩子都是线程对象,  // 因此,清理工作要写在run()里.根据JDK帮助文档,清理工作不能太耗时,要尽快结束,但仍然可以对数据库进行操作.  //意思就是在jvm中增加一个关闭的钩子，当jvm关闭的时候，会执行系统中已经设置的所有通过方法addShutdownHook添加的钩子，  // 当系统执行完这些钩子后，jvm才会关闭。所以这些钩子可以在jvm关闭的时候进行内存清理、对象销毁等操作。  Runtime.getRuntime().addShutdownHook(new Thread(\u0026#34;kafka-shutdown-hook\u0026#34;) { override def run(): Unit = kafkaServerStartable.shutdown() }) // 这里终于到了 kafka 启动了， 本质上就是 KafkaServer.startup()  kafkaServerStartable.startup() // shutdown 之后需要做的一些事  kafkaServerStartable.awaitShutdown() } catch { case e: Throwable =\u0026gt; fatal(\u0026#34;Exiting Kafka due to fatal exception\u0026#34;, e) Exit.exit(1) } Exit.exit(0) } } 然后到了 kafka.server.KafkaServerStartable 和 kafka.server.KafkaServer KafkaServerStartable 包装了一层KafkaServer。本质上 KafkaServerStartable 定义了 KafkaServer 的 几种状态，将属于这几种状态的 error 抽象了出来。\n现在来看看 KafkaServer 的 startup() 启动类\nclass KafkaServer(val config: KafkaConfig, time: Time = Time.SYSTEM, threadNamePrefix: Option[String] = None, kafkaMetricsReporters: Seq[KafkaMetricsReporter] = List()) extends Logging with KafkaMetricsGroup { // 启动、是否关闭、是否启动标识  // 原子方式进行读和写的布尔值  //AtomicBoolean是Java.util.concurrent.atomic包下的原子变量，这个包里面提供了一组原子类。  // 其基本的特性就是在多线程环境下，当有多个线程同时执行这些类的实例包含的方法时，具有排他性，  // 即当某个线程进入方法，执行其中的指令时，不会被其他线程打断，而别的线程就像自旋锁一样，  // 一直等到该方法执行完成，才由JVM从等待队列中选择一个另一个线程进入，这只是一种逻辑上的理解。  // 实际上是借助硬件的相关指令来实现的，不会阻塞线程(或者说只是在硬件级别上阻塞了)。  private val startupComplete = new AtomicBoolean(false) private val isShuttingDown = new AtomicBoolean(false) private val isStartingUp = new AtomicBoolean(false) // CountDownLatch是同步工具类之一，可以指定一个计数值，在并发环境下由线程进行减1操作，  // 当计数值变为0之后，被await方法阻塞的线程将会唤醒，实现线程间的同步。  private var shutdownLatch = new CountDownLatch(1) private val jmxPrefix: String = \u0026#34;kafka.server\u0026#34; private var logContext: LogContext = null var metrics: Metrics = null val brokerState: BrokerState = new BrokerState var dataPlaneRequestProcessor: KafkaApis = null var controlPlaneRequestProcessor: KafkaApis = null var authorizer: Option[Authorizer] = None // 监听 socket 请求  var socketServer: SocketServer = null // 请求资源池  var dataPlaneRequestHandlerPool: KafkaRequestHandlerPool = null var controlPlaneRequestHandlerPool: KafkaRequestHandlerPool = null // 日志管理  var logDirFailureChannel: LogDirFailureChannel = null var logManager: LogManager = null // 分区副本管理  var replicaManager: ReplicaManager = null var adminManager: AdminManager = null var tokenManager: DelegationTokenManager = null // 动态 config 处理  var dynamicConfigHandlers: Map[String, ConfigHandler] = null var dynamicConfigManager: DynamicConfigManager = null var credentialProvider: CredentialProvider = null var tokenCache: DelegationTokenCache = null var groupCoordinator: GroupCoordinator = null var transactionCoordinator: TransactionCoordinator = null var kafkaController: KafkaController = null var kafkaScheduler: KafkaScheduler = null var metadataCache: MetadataCache = null var quotaManagers: QuotaFactory.QuotaManagers = null private var _zkClient: KafkaZkClient = null val correlationId: AtomicInteger = new AtomicInteger(0) val brokerMetaPropsFile = \u0026#34;meta.properties\u0026#34; val brokerMetadataCheckpoints = config.logDirs.map(logDir =\u0026gt; (logDir, new BrokerMetadataCheckpoint(new File(logDir + File.separator + brokerMetaPropsFile)))).toMap private var _clusterId: String = null private var _brokerTopicStats: BrokerTopicStats = null def clusterId: String = _clusterId // Visible for testing  private[kafka] def zkClient = _zkClient private[kafka] def brokerTopicStats = _brokerTopicStats newGauge( \u0026#34;BrokerState\u0026#34;, new Gauge[Int] { def value = brokerState.currentState } ) newGauge( \u0026#34;ClusterId\u0026#34;, new Gauge[String] { def value = clusterId } ) newGauge( \u0026#34;yammer-metrics-count\u0026#34;, new Gauge[Int] { def value = { com.yammer.metrics.Metrics.defaultRegistry.allMetrics.size } } ) /** * Start up API for bringing up a single instance of the Kafka server. * Instantiates the LogManager, the SocketServer and the request handlers - KafkaRequestHandlers */ // Kafka 真正 broker 的启动类  def startup() { try { info(\u0026#34;starting\u0026#34;) // 如果脚本再次在本机启动这个类，  if (isShuttingDown.get) throw new IllegalStateException(\u0026#34;Kafka server is still shutting down, cannot re-start!\u0026#34;) if (startupComplete.get) return val canStartup = isStartingUp.compareAndSet(false, true) if (canStartup) { brokerState.newState(Starting) /* setup zookeeper */ // 启动 broker 第一步就是 初始化 zk client  initZkClient(time) /* Get or create cluster_id */ // 确定 cluser id， 包装 n 层 直到配置文件 /cluster/id  _clusterId = getOrGenerateClusterId(zkClient) info(s\u0026#34;Cluster ID = $clusterId\u0026#34;) /* generate brokerId */ // 获取 broker id  val (brokerId, initialOfflineDirs) = getBrokerIdAndOfflineDirs config.brokerId = brokerId logContext = new LogContext(s\u0026#34;[KafkaServer id=${config.brokerId}] \u0026#34;) this.logIdent = logContext.logPrefix // initialize dynamic broker configs from ZooKeeper. Any updates made after this will be  // applied after DynamicConfigManager starts.  // Kafka 支持动态修改 config （都存 zk 上）  config.dynamicConfig.initialize(zkClient) /* start scheduler */ // 启动调度器 A scheduler based on java.util.concurrent.ScheduledThreadPoolExecutor  // It has a pool of kafka-scheduler- threads that do the actual work.  kafkaScheduler = new KafkaScheduler(config.backgroundThreads) kafkaScheduler.startup() /* create and configure metrics */ val reporters = new util.ArrayList[MetricsReporter] reporters.add(new JmxReporter(jmxPrefix)) val metricConfig = KafkaServer.metricConfig(config) metrics = new Metrics(metricConfig, reporters, time, true) /* register broker metrics */ _brokerTopicStats = new BrokerTopicStats quotaManagers = QuotaFactory.instantiate(config, metrics, time, threadNamePrefix.getOrElse(\u0026#34;\u0026#34;)) notifyClusterListeners(kafkaMetricsReporters ++ metrics.reporters.asScala) logDirFailureChannel = new LogDirFailureChannel(config.logDirs.size) /* start log manager */ // 启动 Log Manager  logManager = LogManager(config, initialOfflineDirs, zkClient, brokerState, kafkaScheduler, time, brokerTopicStats, logDirFailureChannel) logManager.startup() metadataCache = new MetadataCache(config.brokerId) // Enable delegation token cache for all SCRAM mechanisms to simplify dynamic update.  // This keeps the cache up-to-date if new SCRAM mechanisms are enabled dynamically.  tokenCache = new DelegationTokenCache(ScramMechanism.mechanismNames) credentialProvider = new CredentialProvider(ScramMechanism.mechanismNames, tokenCache) // Create and start the socket server acceptor threads so that the bound port is known.  // Delay starting processors until the end of the initialization sequence to ensure  // that credentials have been loaded before processing authentications.  // 启动socket server，准备对外服务了! 9092 在启动前面的内部类后 对外 服务  socketServer = new SocketServer(config, metrics, time, credentialProvider) socketServer.startup(startupProcessors = false) /* start replica manager */ // 复制管理  replicaManager = createReplicaManager(isShuttingDown) replicaManager.startup() // broker 相关信息注册到 zk 上，host:port 和防止 controller 脑裂的 epoch  // 直到这步 真正注册 到 /broker/ids 算是加入到集群中了  val brokerInfo = createBrokerInfo val brokerEpoch = zkClient.registerBroker(brokerInfo) // Now that the broker id is successfully registered, checkpoint it  checkpointBrokerId(config.brokerId) /* start token manager */ tokenManager = new DelegationTokenManager(config, tokenCache, time , zkClient) tokenManager.startup() /* start kafka controller */ // 启动kafka controller  kafkaController = new KafkaController(config, zkClient, time, metrics, brokerInfo, brokerEpoch, tokenManager, threadNamePrefix) kafkaController.startup() adminManager = new AdminManager(config, metrics, metadataCache, zkClient) /* start group coordinator */ // Hardcode Time.SYSTEM for now as some Streams tests fail otherwise, it would be good to fix the underlying issue  groupCoordinator = GroupCoordinator(config, zkClient, replicaManager, Time.SYSTEM) groupCoordinator.startup() /* start transaction coordinator, with a separate background thread scheduler for transaction expiration and log loading */ // Hardcode Time.SYSTEM for now as some Streams tests fail otherwise, it would be good to fix the underlying issue  transactionCoordinator = TransactionCoordinator(config, replicaManager, new KafkaScheduler(threads = 1, threadNamePrefix = \u0026#34;transaction-log-manager-\u0026#34;), zkClient, metrics, metadataCache, Time.SYSTEM) transactionCoordinator.startup() /* Get the authorizer and initialize it if one is specified.*/ authorizer = Option(config.authorizerClassName).filter(_.nonEmpty).map { authorizerClassName =\u0026gt; val authZ = CoreUtils.createObject[Authorizer](authorizerClassName) authZ.configure(config.originals()) authZ } val fetchManager = new FetchManager(Time.SYSTEM, new FetchSessionCache(config.maxIncrementalFetchSessionCacheSlots, KafkaServer.MIN_INCREMENTAL_FETCH_SESSION_EVICTION_MS)) /* start processing requests */ // 从这里开始， 准备 完成， 开始处理外界消息。  dataPlaneRequestProcessor = new KafkaApis(socketServer.dataPlaneRequestChannel, replicaManager, adminManager, groupCoordinator, transactionCoordinator, kafkaController, zkClient, config.brokerId, config, metadataCache, metrics, authorizer, quotaManagers, fetchManager, brokerTopicStats, clusterId, time, tokenManager) // 起线程池，传入 socket server 对象  dataPlaneRequestHandlerPool = new KafkaRequestHandlerPool(config.brokerId, socketServer.dataPlaneRequestChannel, dataPlaneRequestProcessor, time, config.numIoThreads, s\u0026#34;${SocketServer.DataPlaneMetricPrefix}RequestHandlerAvgIdlePercent\u0026#34;, SocketServer.DataPlaneThreadPrefix) socketServer.controlPlaneRequestChannelOpt.foreach { controlPlaneRequestChannel =\u0026gt; controlPlaneRequestProcessor = new KafkaApis(controlPlaneRequestChannel, replicaManager, adminManager, groupCoordinator, transactionCoordinator, kafkaController, zkClient, config.brokerId, config, metadataCache, metrics, authorizer, quotaManagers, fetchManager, brokerTopicStats, clusterId, time, tokenManager) controlPlaneRequestHandlerPool = new KafkaRequestHandlerPool(config.brokerId, socketServer.controlPlaneRequestChannelOpt.get, controlPlaneRequestProcessor, time, 1, s\u0026#34;${SocketServer.ControlPlaneMetricPrefix}RequestHandlerAvgIdlePercent\u0026#34;, SocketServer.ControlPlaneThreadPrefix) } // 监控相关  Mx4jLoader.maybeLoad() /* Add all reconfigurables for config change notification before starting config handlers */ config.dynamicConfig.addReconfigurables(this) /* start dynamic config manager */ dynamicConfigHandlers = Map[String, ConfigHandler](ConfigType.Topic -\u0026gt; new TopicConfigHandler(logManager, config, quotaManagers, kafkaController), ConfigType.Client -\u0026gt; new ClientIdConfigHandler(quotaManagers), ConfigType.User -\u0026gt; new UserConfigHandler(quotaManagers, credentialProvider), ConfigType.Broker -\u0026gt; new BrokerConfigHandler(config, quotaManagers)) // Create the config manager. start listening to notifications  dynamicConfigManager = new DynamicConfigManager(zkClient, dynamicConfigHandlers) dynamicConfigManager.startup() // socket server 开始对外服务  socketServer.startDataPlaneProcessors() socketServer.startControlPlaneProcessor() brokerState.newState(RunningAsBroker) // 修改初始 new KafkaServer 类的状态，启动完成  shutdownLatch = new CountDownLatch(1) startupComplete.set(true) isStartingUp.set(false) AppInfoParser.registerAppInfo(jmxPrefix, config.brokerId.toString, metrics, time.milliseconds()) info(\u0026#34;started\u0026#34;) } } catch { case e: Throwable =\u0026gt; fatal(\u0026#34;Fatal error during KafkaServer startup. Prepare to shutdown\u0026#34;, e) isStartingUp.set(false) shutdown() throw e } } 核心 经过以上分析，kafka 大致的启动流程我们就知道了，接下来是看 kafka 内部 各个 startup 出来的模块，到底每个是负责什么的。\n比方说: KafkaScheduler是一个基于java.util.concurrent.ScheduledThreadPoolExecutor的调度器，它内部是以前缀kafka-scheduler-xx（xx是线程序列号）的线程池处理真正的工作。\n","href":"/kafka/kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%B9%8Bbroker%E5%90%AF%E5%8A%A8/","title":"Kafka源码阅读之broker启动"},{"content":" Kafka 源码阅读 这里是一些kafka源码阅读笔记\n","href":"/kafka/intro/","title":"Intro"},{"content":"","href":"/authors/","title":"Authors"},{"content":"","href":"/categories/","title":"Categories"},{"content":"","href":"/tags/github/","title":"github"},{"content":" How to hugo 日常使用篇  本篇介绍如何发布一篇文章并编写shell脚本快捷发布/\n  How to hugo 日常使用篇  本地撰写博文 发布 shell 脚本自动发布 TODO Ref    本篇文章介绍如何发布一篇文章并上传到网页端. 一共只有两个步骤\n 本地撰写博文 cd ./mytopia hugo server -D // 此时开启的是fast render 模式, 会热更新你的博文编辑. hugo new /posts/new_intro.md // 创建一篇新的博文 发布 cd ./mytopia hugo -D // 默认hugo new出来的文章都有个标签是草稿, -D 指的是build 所有草稿 cd build git add . git commit -m \u0026#34;xxx\u0026#34; git push original master 注意, 以上这部分推送之后, 页面就更新了, 但是其实本体文件并没有上传到github保存, 建议先如下操作:\ncd ./mytopia hugo -D git add . git commit -m \u0026#34;xxx\u0026#34; git push original master 由于每次想写文章都要敲以上那么多条命令, 当然我们还是写一个shell脚本更加方便.\nshell 脚本自动发布 deploy.sh 使用方法:\n 复制如下脚本并chomd + x deploy.sh 自动commit ./deploy.sh 自动push 到github并更新page, 或者./deploy.sh + xxx\n#!/bin/sh  # If a command fails then the deploy stops set -e printf \u0026#34;\\033[0;32mDeploying updates to tangzhongham...\\033[0m\\n\u0026#34; # Build the project. hugo -D # if using a theme, replace with `hugo -t \u0026lt;YOURTHEME\u0026gt;` # push your files to github msg=\u0026#34;saving file and rebuilding site $(date)\u0026#34; if [ -n \u0026#34;$*\u0026#34; ]; then msg=\u0026#34;$*\u0026#34; fi git add . git commit -m \u0026#34;$msg\u0026#34; # Push source and build repos. git push origin master # Go To Public folder cd public # Add changes to git. git add . # Commit changes. git commit -m \u0026#34;$msg\u0026#34; # Push source and build repos. git push origin master printf \u0026#34;upload success, enjoy your journey! \u0026#34;  TODO deployment 文件撰写  创建了一个改版的sh文件,不知道咋样,试试.\nsearch 功能暂时去掉  一个很坑的事情, 按照文档添加 search 则会把homepage的介绍挤掉. 放到sidebar 则无法使用\u0026hellip; 暂时去掉搜索吧.\nRef minimo模版\nhugo官方部署文档\n","href":"/intro/how_to_hugo%E6%97%A5%E5%B8%B8%E4%BD%BF%E7%94%A8%E7%AF%87/","title":"How_to_hugo日常使用篇"},{"content":"","href":"/tags/hugo/","title":"hugo"},{"content":"","href":"/intro/","title":"Intros"},{"content":"","href":"/tags/markdown/","title":"markdown"},{"content":"","href":"/tags/","title":"Tags"},{"content":"","href":"/categories/tutorial/","title":"tutorial"},{"content":"","href":"/authors/tzh/","title":"tzh"},{"content":" How to hugo 安装篇  本篇介绍如何安装 hugo 并将 blog 部署到 github pages.\n ","href":"/intro/how_to_hugo%E5%AE%89%E8%A3%85%E7%AF%87/","title":"How_to_hugo安装篇"},{"content":" hugo 日志操作流程 [toc]\n 本篇文章介绍如何发布一篇文章并上传到网页端. 一共只有两个步骤\n 本地撰写博文 cd ./mytopia hugo server -D // 此时开启的是fast render 模式, 会热更新你的博文编辑. hugo new /posts/new_intro.md // 创建一篇新的博文 发布 cd ./mytopia hugo -D cd build git add . git commit -m \u0026#34;xxx\u0026#34; git push original master 注意, 以上这部分推送之后, 页面就更新了, 但是其实本体文件并没有上传到github保存, 建议先如下操作:\ncd ./mytopia hugo -D git add . git commit -m \u0026#34;xxx\u0026#34; git push original master deploy文件:\nTODO deployment 文件撰写  创建了一个改版的sh文件,不知道咋样,试试.\n一个很坑的事情, 按照文档添加 search 则会把homepage的介绍挤掉. 放到sidebar 则无法使用\u0026hellip; 暂时去掉搜索吧.\n文本 #!/bin/sh  # If a command fails then the deploy stops set -e printf \u0026#34;\\033[0;32mDeploying updates to tangzhongham...\\033[0m\\n\u0026#34; # Build the project. hugo -D # if using a theme, replace with `hugo -t \u0026lt;YOURTHEME\u0026gt;` # push your files to github msg=\u0026#34;saving file and rebuilding site $(date)\u0026#34; if [ -n \u0026#34;$*\u0026#34; ]; then msg=\u0026#34;$*\u0026#34; fi git add . git commit -m \u0026#34;$msg\u0026#34; # Push source and build repos. git push origin master # Go To Public folder cd public # Add changes to git. git add . # Commit changes. git commit -m \u0026#34;$msg\u0026#34; # Push source and build repos. git push origin master printf \u0026#34;upload success, enjoy your journey! \u0026#34; ps: 发现该shell脚本自带传参功能了...","href":"/posts/new_intro/","title":"New_intro"},{"content":"","href":"/posts/","title":"Posts"},{"content":"","href":"/intro/how_to_hugo/","title":"How_to_hugo"},{"content":" 2019 年 11 月  2019 年 11 月  1119 - 1126 11 19 周二  Thoughts TODO LIST     This is for PRIVATE ONLY !!!\n 1119 - 1126 11 19 周二 Thoughts 今天终于把页面部署好了~ 然后可以舒舒服服的发布,然后在哪里都能看啦.\nTODO LIST deploy 脚本研究 git submodule 是什么意思 文章润色~ 明天要开始输出 kafka 的东西啦~ 然后 Spark 源码也要看起来了!!!  ","href":"/diary/201911/","title":"201911"},{"content":"","href":"/tags/create/","title":"create"},{"content":"","href":"/diary/","title":"Diaries"},{"content":"","href":"/tags/diary/","title":"diary"},{"content":"","href":"/categories/diary/","title":"diary"},{"content":"","href":"/tags/orz.../","title":"ORZ..."},{"content":" How to deploy your hugo sites to Github Pages  How to deploy your hugo sites to Github Pages  部署到 Github 个人页面 常见错误 TODO LIST   部署到 Github 个人页面  在github 分别建立 mytopia 和 \u0026lt;username\u0026gt;.github.io 的仓库，前者用来存放网页的源文件，后者用来存放最终展示的网站内容\n 进入之前教程中的本地目录\ncd /mytopia 将 mytopia 项目关联到远程的 mytopia 仓库\ngit remote add origin git@github.com/TangZhongham/mytopia.git 将本地网站全部推送到远程的 mytopia 仓库\ngit push -u origin master  可能会出现push 不了的原因。可能需要你 git add .然后git commit -m \u0026quot;first commit\u0026quot;\n前文要注意git submodule 和 git init，所以这边才不用git init了。src refspec master does not match 错误是由于没有 add 东西就 push 了。\n 此时所有代码已经被推送到 github 上了。\n 确保服务正常，并确保根目录下没有 /public文件夹。\nrm -r /public 关闭hugo服务器ctrl+C，执行以下命令创建 public 子模块，将用于github page 展示。\ngit submodule add -b master https://github.com/TangZhongham/tangzhongham.github.io.git public 执行hugo命令，自动创建 public 文件夹。然后将代码提交到远程 mytopia 仓库\nhugo cd public git status git add . git commit -m \u0026#34;first commit\u0026#34; git push -u origin master  不行，重新rm -r public 试试。tangzhongham.github.io 建点东西，好像听说不能完全为空。\n删完又 git add git commit/ git push -u origin master 了一波。\n重复第7步\ncd ./public git pull --allow-unrelated-histories git push 解决两边不一样的问题（http那边创建了个README）  现在的操作流程就是说，先改文章。然后 /mytopia 下面 hugo -buildDrafts 然后 git add/commit/push 三连，之后 去 /build 里面 三连，页面才能更新。 (发现不成功的原因是 -buildDrafts 少了一个 - 符号, 要么是-D 要么是 \u0026ndash;buildDrafts)\n现在他妈js 又404 了，搞毛线 新问题好像是在外面 git push 之后，里面再 git status 就 检测不到了，然后页面上 mytopia 的 public 被 push 了，但是 io 的没有。 不知道404 是不是由于这个原因。尝试 hugo -buildDrafts 之后先提交里面的试试。\n常见错误 TODO LIST 预备流程：go/git/hugo 分两篇，怎样本地启动，怎样部署。注意事项（http 空文件问题） 可以重新部署一次玩（好累，往后稍稍吧) Git submodule 的使用，为啥两边要更新两次 deploy 脚本的编写 Enjoy！  ","href":"/intro/how_to_github_pages/","title":"How_to_github_pages"},{"content":" How to Hugo [toc]\n安装篇 Git 安装 略\nHugo 安装 Windows 下载二进制文件: Windows 安装其实要比 Mac 舒服一些.找到 binary 二进制文件 的Releases, 下载下来安装就行. 下载链接\n添加到Path: 不会的可以谷歌.\nMac 诚然, 我一开始当然是愉快的使用 brew install hugo 的方式. 问题来了\u0026hellip;由于方方面的原因,这样下载的 hugo 版本太低了,和我喜欢的主题有冲突, 所以 mac 也老老实实和 win 一样找二进制安装然后配置path 吧~\n ps: Mac 软链接有点小坑, 没搞定的谷歌可以解决.\n 启动篇  Hugo 是目前最舒服的markdown 静态网站方案了. 简单五步开始搭建博客吧.\n 第一步: 网站 由于静态网站的便捷性, hugo 建立一个网站只需要一条命令.\nhugo new site mytopiia 此时 hugo 生成的目录结构如下: mytopiia ├── archetypes # 存放生成博客的模版 │ └── default.md ├── config.toml # tommy 的改良版 yaml ├── content # 你写markdown 的地方 ├── data # Hugo 处理的数据 ├── layouts # 布局文件 ├── static # 静态文件 └── themes # 主题 严格意义上来说, 这一步已经可以部署你的“网站”了. 先挑一个主题吧.\n第二步: 主题 选好主题后, 这里涉及到一些 git 的知识, 先照着敲就对了.\ncd mytopiia # 下载你喜欢的 theme, 下面是我喜欢的. git init git submodule add https://github.com/panr/hugo-theme-terminal.git themes/terminal # 把主题名称添加到 config 里生效. echo \u0026#39;theme = \u0026#34;terminal\u0026#34;\u0026#39; \u0026gt;\u0026gt; config.toml 第三步: Config 第四步: Markdown m\n第五步: Server 润色篇 ","href":"/intro/how_to_hugo_1/","title":"How_to_hugo_1"},{"content":" All cowardice comes from not loving or not loving well, which is the same thing.\n ","href":"/","title":""},{"content":" 1. Markdown 5分钟使用指南  注意: 该主题的toc渲染有点问题,不支持1.1.1 这种表达(和 visual studio code 里面冲突)   1. Markdown 5分钟使用指南  1.1. Why Markdown How to Markdown 1.2.1. 结构 1.2.2. 段落  1.2.2.1. 分隔符 1.2.2.2. 引用 1.2.2.3. 代码块 1.2.2.3.1. 单行代码 1.2.2.3.2. 多行代码  1.2.3. 句子  1.2.3.1. 换行 1.2.3.2. Bullet Dot  1.2.4. 文本  1.2.4.1. 链接  1.3. Others 1.3.1. 杂   1.1. Why Markdown  Markdown is a lightweight markup language that you can use to add formatting elements to plaintext text documents.\n Markdown 本质上就是一种标记语言，让你在不需要过度关注文章结构的同时，提供了符合逻辑的文章结构。\nHow to Markdown 正如以上所说，Markdown 只是为了让你更舒服的组织好文章架构，那么从以下几个方面来使用则很符合逻辑。\n1.2.1. 结构 Markdown 把一篇文章分为如下结构:\n一级标题只能有一个，等价于文章的标题，所有其他等级标题都在一级标题下面。\n1.2.2. 段落 正文直接手写就行。\n1.2.2.1. 分隔符 如下：\n1.2.2.2. 引用  这样就可以引用别人的话。\n 引用功能可以嵌套。\n 哈哈\n   1.2.2.3. 代码块 1.2.2.3.1. 单行代码 单行代码可以这么写：def\n1.2.2.3.2. 多行代码 多行代码一样的，同时在后接 python 等可以支持不同语法的代码高亮。\ndef hello_world(): \u0026#34;\u0026#34;\u0026#34; 代码里面就一样的 \u0026#34;\u0026#34;\u0026#34; pass 1.2.3. 句子 1.2.3.1. 换行 Markdown 的换行有点傻逼。 可以这么换(貌似没有更好的解决办法)\n1.2.3.2. Bullet Dot 这样就行 会自动往后添加，不用每个都手打，放心。  1.2.4. 文本 文本的内容就比较有趣了。 比方说可以加粗，可以划去内容，可以 斜体字 ，也可以下划线。\n1.2.4.1. 链接 可以直接这样\n图片的话： 1.3. Others 1.3.1. 杂 ","href":"/posts/how_to_hugo/","title":"How_to_hugo"},{"content":" Markdown 5分钟使用指南  Markdown 5分钟使用指南  Why Markdown How to Markdown 结构 段落  分隔符 引用 代码块 单行代码 多行代码  句子  换行 Bullet Dot  文本  链接  Others 杂   Why Markdown  Markdown is a lightweight markup language that you can use to add formatting elements to plaintext text documents.\n Markdown 本质上就是一种标记语言，让你在不需要过度关注文章结构的同时，提供了符合逻辑的文章结构。\nHow to Markdown 正如以上所说，Markdown 只是为了让你更舒服的组织好文章架构，那么从以下几个方面来使用则很符合逻辑。\n结构 Markdown 把一篇文章分为如下结构:\n 这是一级标题 这是二级标题 这是三级标题 这是四级标题 这是五级标题  一级标题只能有一个，等价于文章的标题，所有其他等级标题都在一级标题下面。\n段落 正文直接手写就行。\n分隔符 如下：\n引用  这样就可以引用别人的话。\n 引用功能可以嵌套。\n 哈哈\n   代码块 单行代码 单行代码可以这么写：def\n多行代码 多行代码一样的，同时在后接 python 等可以支持不同语法的代码高亮。\ndef hello_world(): \u0026#34;\u0026#34;\u0026#34; 代码里面就一样的 \u0026#34;\u0026#34;\u0026#34; pass 句子 换行 Markdown 的换行有点傻逼。 可以这么换(貌似没有更好的解决办法)\nBullet Dot 这样就行 会自动往后添加，不用每个都手打，放心。  文本 文本的内容就比较有趣了。 比方说可以加粗，可以划去内容，可以 斜体字 ，也可以下划线。\n链接 可以直接这样\nhttp://www.hao123.com\n图片的话： Others 杂 ","href":"/posts/how_to_markdown/","title":"How_to_markdown"},{"content":"","href":"/categories/posts/","title":"posts"},{"content":" Hello! 有问题欢迎交流!\n微信: tzh-1166\n邮箱: 13122260573@163.com\n","href":"/about/","title":""},{"content":"","href":"/page/search/","title":""},{"content":"","href":"/page/","title":"Pages"},{"content":"","href":"/series/","title":"Series"}]
