[{"content":"","href":"/java/","title":"Javas"},{"content":"","href":"/java/java%E5%AD%A6%E4%B9%A0-jvm/","title":"Java学习 JVM"},{"content":" Java 并发  记录在各个地方学到的小知识, 起常看常新和弥补作用\n 并发知识索引:\n什么是线程, 线程的状态, 线程可以干嘛, 为了解决线程干嘛带来的新问题的解决方案.\n《Java 核心技术》 Runnable 状态是因为: 此时线程可能正在运行也可能没在运行, 要由操作系统为线程提供具体的运行时间, 线程调度的细节依赖于操作系统提供的服务.\n线程的状态: New、Runnable、Terminated、+ 并发所产生的三个condition: Blocked、Waiting、Timed Waiting.\n在 Race Condition 竞态条件下, 同步的几种锁使用方式:\n synchronized, 不够灵活 ReentrantLock, 灵活, 需要在 finally unlock 使用object 自带的内部锁 锁自己(flink 常用) synchronized (lock) {}  条件对象的使用需要注意: if a \u0026gt; 0 , xxx , 这两步中间可能就导致不一致, 可以用 Condition 来操作\n如果是实例字段的话使用 volatile 关键字.\nstop 方法不会执行 finally 语句块, 导致一些锁得不到释放, 因此不再使用.\nBlockingQueue 常用的几个基本实现原理. 起线程开销大, 涉及到和操作系统的交互, 因此有线程池. Executors 常用方法. Fork Join 基本原理 (akka 使用)  开源世界 ","href":"/java/java%E5%AD%A6%E4%B9%A0-%E5%B9%B6%E5%8F%91/","title":"Java学习 并发"},{"content":"","href":"/java/java%E5%AD%A6%E4%B9%A0-%E5%AE%B9%E5%99%A8/","title":"Java学习 容器"},{"content":"","href":"/java/java%E5%AD%A6%E4%B9%A0-%E5%9F%BA%E7%A1%80/","title":"Java学习 基础"},{"content":" JVM原理入门  tzh 2020/05/19./\n  JVM原理入门  Why JVM Why Java Java、JDK、JRE JVM 概论 什么是 JVM JVM 概览 前端编译/Class 文件  Class 文件结构  后端编译 虚拟机类加载机制  加载 验证 准备 解析 初始化 使用 卸载  内存/堆/GC 私有  程序计数器 Java 虚拟机栈 + 本地方法栈  公有  方法区 + 常量池 堆 堆的分布 GC 词汇 一般性的GC流程 一般性的 YGC/FGC 堆内存的具体分布  为什么有两个 Survivor 区   直接内存 常用命令 k8s 上极其方便的玩法 jps jinfo jstat  YGC 和 Survivor Thoughts  jmap jstack Slipstream 常用分析 (待续) 作业 Ref   Why JVM 以下问题很是让人头疼?\n 内存溢出? GC FGC YGC? server 没响应 4040页面上不去? executor 一跑就挂executor lost? beeline 作业提交不上去? \u0026hellip;\u0026hellip;  你必须学会看懂日志吧。那么你就必须要看得懂 GC 日志，这是 Java 虚拟机内容的一部分。你看懂了 GC 日志，那么你就得明白什么是年轻代、老年代、永久代、元数据区等，这些就是 Java 虚拟机的内存模型。你懂了 Java 虚拟机的内存模型，那你就得知道 Java 虚拟机是如何进行垃圾回收的，它们使用的垃圾回收算法是怎样的，它们有何优缺点。接下来就是各种垃圾回收器的特性\u0026hellip;\u0026hellip;\nWhy Java Java 出生时主要解决的两个问题:\n 一次编写, 到处运行 (Write once, run anywhere) 相对安全的内存管理和访问机制, 避免了大部分内存泄露和指针越界(语言往人这边更加偏向化)  以前程序员写代码需要分平台, 在linux能跑的代码放到win上面就跑不了了. 然后C/C++自己申请内存还得自己自己free. 讲白了就是你手里的代码是跟机器又远了一步, 跟概念抽象又近了一步.\n比方说, 你写了一个 hello world 的 C程序, 在linux编译完后的可执行文件是不可以在windows运行的. (generally) 但是你没听说写一段 Java 代码还分 windows/linux 吧. 这就是 JVM 的优势了.\nJava、JDK、JRE Java 社区把 Java技术体系 分为以下四个部分:\n Java 程序设计语言 各种平台款式的 JVM (java -verion) Class 文件格式 Java API 类库 + 第三方类库  JRE = Java Runtime Environment = JVM + Java 核心类库. 支持 Java 程序运行的标准环境\nJDK = JRE + 开发、诊断工具. 用于支持 Java 程序开发的最小环境\nJVM 概论 什么是 JVM JVM，全称Java Virtual Machine，英文为Java虚拟机，简单的探讨一下虚拟机这三个字，对后面的学习也是挺舒服的。百度百科描述说，“虚拟机（Virtual Machine）指通过软件模拟的具有完整硬件系统功能的、运行在一个完全隔离环境中的完整计算机系统”，但是虚拟机本质还是该计算机系统的一个进程，可以类比香港澳门具有高度自治，但本质上他们还是属于中国的。为了方便描述，我们把整个计算机当成一幢大楼，而虚拟机则是某一个楼层。大楼划分了一个区域给一个楼层，让这个楼层自己管理自己，也就对应着，计算机划分了一个内存给JVM，让JVM自己管理自己。\n与其他语言不同，Java 语言并不直接将代码编译成与系统有关的机器码，而是编译成一种特定的语言规范，这种语言规范我们称之为字节码。无论 Java 程序要在 Windows 系统，还是 Mac OSX 系统，抑或是 Linux 系统，它首先都得编译成字节码文件，之后才能运行。\n但即使编译成字节码文件了，各个系统还是无法明白字节码文件的内容，这时候就需要 Java 虚拟机的帮助了。Java 虚拟机会解析字节码文件的内容，并将其翻译为各操作系统能理解的机器码。\nJava的程序编译的最终样子是.class文件，不同虚拟机的对每一个.class文件的翻译结果都是一致的。而对于C／C++而言，编译生成的是纯二进制的机器指令，是直接面对计算机系统的内存，但是，java程序的编译结果是面向JVM，是要交付给JVM，让他再做进一步处理从而让计算机识别运行，这就是所谓的“屏蔽掉各种硬件和操作系统的内存访问差异”。\nJVM 概览  代码编译的结果从本地机器码转变为字节码, 是储存格式发展的一小步, 确实编程语言发展的一大步\n 前端编译/Class 文件 public class Helloworld{ public static void main(String[] args) { System.out.println(\u0026#34;hello world\u0026#34;); } }javac Helloworld.java ll Helloworld.java // 二进制的字节码 Helloworld.class [root@linux-pm-0-37 tzh]# java Helloworld hello world 我们运行 javac 命令的过程，其实就是 javac 编译器解析 Java 源代码，并生成字节码文件的过程。说白了，其实就是使用 javac 编译器把 Java 语言规范转化为字节码语言规范。javac 编译器的处理过程可以分为下面四个阶段：\n第一个阶段：词法、语法分析。在这个阶段，JVM 会对源代码的字符进行一次扫描，最终生成一个抽象的语法树。简单地说，在这个阶段 JVM 会搞懂我们的代码到底想要干嘛。就像我们分析一个句子一样，我们会对句子划分主谓宾，弄清楚这个句子要表达的意思一样。\n第二个阶段：填充符号表。我们知道类之间是会互相引用的，但在编译阶段，我们无法确定其具体的地址，所以我们会使用一个符号来替代。在这个阶段做的就是类似的事情，即对抽象的类或接口进行符号填充。等到类加载阶段，JVM 会将符号替换成具体的内存地址。\n第三个阶段：注解处理。我们知道 Java 是支持注解的，因此在这个阶段会对注解进行分析，根据注解的作用将其还原成具体的指令集。\n第四个阶段：分析与字节码生成。到了这个阶段，JVM 便会根据上面几个阶段分析出来的结果，进行字节码的生成，最终输出为 class 文件。\nClass 文件结构  魔数与Class文件版本 常量池 访问标志 类索引、父类索引、接口索引 字段表集合 方法表集合 属性表集合  后端编译 AOT: Ahead of Time, 运行前编译\nJIT: Just in Time, 动态(即时)编译，边运行边编译\n这两种方式的区别在于，前者启动速度快但运行速度慢，而后者启动速度慢但运行速度快。至于为什么会这样，其原因很简单。因为解释器不需要像 JIT 编译器一样，将所有字节码都转化为机器码，自然就少去了优化的时间。而当 JIT 编译器完成第一次编译后，其会将字节码对应的机器码保存下来，下次可以直接使用。而我们知道，机器码的运行效率肯定是高于 Java 解释器的。所以在实际情况中，为了运行速度以及效率，我们通常采用两者相结合的方式进行 Java 代码的编译执行。\n所以一般都是默认两种一起上.\n[root@linux-pm-0-37 tzh]# java -version java version \u0026#34;1.8.0_191\u0026#34; Java(TM) SE Runtime Environment (build 1.8.0_191-b12) Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode) [root@linux-pm-0-37 tzh]# java -Xcomp -version java version \u0026#34;1.8.0_191\u0026#34; Java(TM) SE Runtime Environment (build 1.8.0_191-b12) Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, compiled mode) [root@linux-pm-0-37 tzh]# java -Xint -version java version \u0026#34;1.8.0_191\u0026#34; Java(TM) SE Runtime Environment (build 1.8.0_191-b12) Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, interpreted mode) 虚拟机类加载机制 JVM 把描述类的数据从 Class 文件加载到内存, 并对数据进行校验、转换解析、初始化等最终形成能被虚拟机直接使用的 Java类型, 这个过程叫做虚拟机的类加载机制.\n当我们的Java代码编译完成后，会生成对应的 class 文件。接着我们运行java Demo命令的时候，我们其实是启动了JVM 虚拟机执行 class 字节码文件的内容。而 JVM 虚拟机执行 class 字节码的过程可以分为七个阶段：加载、验证、准备、解析、初始化、使用、卸载。\n加载  通过一个类的全限定名(源文件中的全新定名是包名加类名， 包名的各个部分之间，包名和类名之间， 使用点号分割。 如Object类， 在源文件中的全限定名是java.lang.Object )获取定义此类的二进制字节流 将该二进制字节流所代表的静态储存结构转化为 方法区(Method Area) 运行时的数据结构 在内存中生成一个代表这个类的 java.lang.Class 对象, 作为方法区这个类的各种数据的访问入口  加载用的类加载器classloader 分为 启动类加载器 sun.boot.class.path 控制(jinfo 可看) 和 其他加载器.\n注意: 对于任何一个类, 都必须由它的类加载器和这个类本身一起确定在 JVM 的唯一性. inceptor 有个问题: 不支持动态更新UDF. 就是由于用了同一个classloader + UDF 全限定名未改(可能曾加载到method area并且未清掉) 而导致JVM无法确定udf行为不可测.\nWARP-27681 TDH 6.0.1, TDH 6.1, TDH 5.2.3支持不重启服务更新udf jar包 drop permanent function kafka_demo with resource; create permanent function kafka_demo as \u0026lsquo;io.transwarp.udf.KafkaUDF\u0026rsquo; using jar \u0026lsquo;file:///home/wangcheng/marason/udf/udf/target/kafka.jar\u0026rsquo;;\n验证 当 JVM 加载完 Class 字节码文件并在方法区创建对应的 Class 对象之后，JVM 便会启动对该字节码流的校验，只有符合 JVM 字节码规范的文件才能被 JVM 正确执行。这个校验过程大致可以分为下面几个类型：\nJVM规范校验。JVM 会对字节流进行文件格式校验，判断其是否符合 JVM 规范，是否能被当前版本的虚拟机处理。例如：文件是否是以 0x cafe bene开头，主次版本号是否在当前虚拟机处理范围之内等。 代码逻辑校验。JVM 会对代码组成的数据流和控制流进行校验，确保 JVM 运行该字节码文件后不会出现致命错误。例如一个方法要求传入 int 类型的参数，但是使用它的时候却传入了一个 String 类型的参数。一个方法要求返回 String 类型的结果，但是最后却没有返回结果。代码中引用了一个名为 Apple 的类，但是你实际上却没有定义 Apple 类。 当代码数据被加载到内存中后，虚拟机就会对代码数据进行校验，看看这份代码是不是真的按照JVM规范去写的。这个过程对于我们解答问题也没有直接的关系，但是了解类加载机制必须要知道有这个过程。\n准备 当完成字节码文件的校验之后，JVM 便会开始为类变量分配内存并初始化。这里需要注意两个关键点，即内存分配的对象以及初始化的类型。\n内存分配的对象。Java 中的变量有「类变量」和「类成员变量」两种类型，「类变量」指的是被 static 修饰的变量，而其他所有类型的变量都属于「类成员变量」。在准备阶段，JVM 只会为「类变量」分配内存，而不会为「类成员变量」分配内存。「类成员变量」的内存分配需要等到初始化阶段才开始。 例如下面的代码在准备阶段，只会为 factor 属性分配内存，而不会为 website 属性分配内存。\npublic static int factor = 3; public String website = \u0026ldquo;www.cnblogs.com/chanshuyi\u0026rdquo;; 初始化的类型。在准备阶段，JVM 会为类变量分配内存，并为其初始化。但是这里的初始化指的是为变量赋予 Java 语言中该数据类型的零值，而不是用户代码里初始化的值。 例如下面的代码在准备阶段之后，sector 的值将是 0，而不是 3。\npublic static int sector = 3; 但如果一个变量是常量（被 static final 修饰）的话，那么在准备阶段，属性便会被赋予用户希望的值。例如下面的代码在准备阶段之后，number 的值将是 3，而不是 0。\npublic static final int number = 3; 之所以 static final 会直接被复制，而 static 变量会被赋予零值。其实我们稍微思考一下就能想明白了。\n两个语句的区别是一个有 final 关键字修饰，另外一个没有。而 final 关键字在 Java 中代表不可改变的意思，意思就是说 number 的值一旦赋值就不会在改变了。既然一旦赋值就不会再改变，那么就必须一开始就给其赋予用户想要的值，因此被 final 修饰的类变量在准备阶段就会被赋予想要的值。而没有被 final 修饰的类变量，其可能在初始化阶段或者运行阶段发生变化，所以就没有必要在准备阶段对它赋予用户想要的值。\n解析 当通过准备阶段之后，JVM 针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定符 7 类引用进行解析。这个阶段的主要任务是将其在常量池中的符号引用替换成直接其在内存中的直接引用。\n其实这个阶段对于我们来说也是几乎透明的，了解一下就好。\n初始化 到了初始化阶段，用户定义的 Java 程序代码才真正开始执行。在这个阶段，JVM 会根据语句执行顺序对类对象进行初始化，一般来说当 JVM 遇到下面 5 种情况的时候会触发初始化：\n遇到 new、getstatic、putstatic、invokestatic 这四条字节码指令时，如果类没有进行过初始化，则需要先触发其初始化。生成这4条指令的最常见的Java代码场景是：使用new关键字实例化对象的时候、读取或设置一个类的静态字段（被final修饰、已在编译器把结果放入常量池的静态字段除外）的时候，以及调用一个类的静态方法的时候。 使用 java.lang.reflect 包的方法对类进行反射调用的时候，如果类没有进行过初始化，则需要先触发其初始化。 当初始化一个类的时候，如果发现其父类还没有进行过初始化，则需要先触发其父类的初始化。 当虚拟机启动时，用户需要指定一个要执行的主类（包含main()方法的那个类），虚拟机会先初始化这个主类。 当使用 JDK1.7 动态语言支持时，如果一个 java.lang.invoke.MethodHandle实例最后的解析结果 REF_getstatic,REF_putstatic,REF_invokeStatic 的方法句柄，并且这个方法句柄所对应的类没有进行初始化，则需要先出触发其初始化。 看到上面几个条件你可能会晕了，但是不要紧，不需要背，知道一下就好，后面用到的时候回到找一下就可以了。\n使用 当 JVM 完成初始化阶段之后，JVM 便开始从入口方法开始执行用户的程序代码。这个阶段也只是了解一下就可以。\n卸载 当用户程序代码执行完毕后，JVM 便开始销毁创建的 Class 对象，最后负责运行的 JVM 也退出内存。这个阶段也只是了解一下就可以。\n内存/堆/GC  Java 和 C++ 有一堵由内存动态分配和垃圾收集技术所围成的高墙, 墙外的人想进来, 墙内的人却想出来\n 现在对于一个 Java 源文件是如何变成字节码文件，以及字节码文件的含义已经非常清楚了。那么接下来就是让 Java 虚拟机运行字节码文件，从而得出我们最终想要的结果了。在这个过程中，Java 虚拟机会加载字节码文件，将其存入 Java 虚拟机的内存空间中，之后进行一系列的初始化动作，最后运行程序得出结果。\n根据《Java 虚拟机规范》中的说法，Java 虚拟机的内存结构可以分为公有和私有两部分。公有指的是所有线程都共享的部分，指的是 Java 堆、方法区、常量池。私有指的是每个线程的私有数据，包括：PC寄存器、Java 虚拟机栈、本地方法栈。\n私有 程序计数器 程序计数器: Program Counter Register, 是一块很小的内存空间(没有规定OOM), 可以看做是当前线程所执行的字节码的行号指示器. 字节码解释器在工作时就是改变计数器的值来选取下一条需要执行的字节码指令, 分支、循环、跳转、异常处理、线程恢复都依赖这个计数器.\n为什么是私有?\n这是由于 JVM 的多线程是通过线程轮流切换、分配处理器执行时间的方式实现的, 在任意一个确定的时间, 一个处理器(多核处理器就是一个核)只会执行一条线程中的指令. 所以切换后要能回到原位, 每条线程都有独立的程序计数器.\nJava 虚拟机栈 + 本地方法栈 java虚拟机栈是线程私有的，他与线程的声明周期同步。 虚拟机栈描述的是java方法执行的线程内存模型，每个方法执行都会创建一个栈帧，栈帧包含局部变量表、操作数栈、动态连接、方法出口等。(规定了 OOM + StackOverflow)\n注意: 一条n长的SQL可能会导致 StackOverflow , 可以通过调整 xss (默认64位为 1024k) HotSpot 虚拟机将 Java 虚拟机栈 + 本地方法栈 放在一起, 只能通过 xss 一起调节\n[root@linux-pm-0-37 tzh]# java -XX:+PrintFlagsFinal -version | grep ThreadStackSize intx CompilerThreadStackSize = 0 {pd product} intx ThreadStackSize = 1024 {pd product} intx VMThreadStackSize = 1024 {pd product} java version \u0026#34;1.8.0_191\u0026#34; Java(TM) SE Runtime Environment (build 1.8.0_191-b12) Java HotSpot(TM) 64-Bit Server VM (build 25.191-b12, mixed mode) 当 Java 虚拟机使用其他语言（例如 C 语言）来实现指令集解释器时，也会使用到本地方法栈。如果 Java 虚拟机不支持 natvie 方法，并且自己也不依赖传统栈的话，可以无需支持本地方法栈。\n公有 线程公有的部分分为: 堆、方法区、常量池.\n方法区 + 常量池 方法区: Method Area, 指的是存储 Java 类字节码数据的一块区域，它存储了每一个类的结构信息，例如运行时常量池、字段和方法数据、构造方法等。可以看到常量池其实是存放在方法区中的，但《Java 虚拟机规范》将常量池和方法区放在同一个等级上，这点我们知晓即可。\n方法区在不同版本的虚拟机有不同的表现形式，例如在 1.7 版本的 HotSpot 虚拟机中，方法区被称为永久代（Permanent Space），而在 JDK 1.8 中则被称之为 MetaSpace。\n这是因为 JDK 1.8 之前, HotSpot 的设计团队选择把垃圾收集器的分代设计扩展到方法区, 或者说使用 永久代 来实现方法区, 从而免去专门编写内存管理代码. 由于可能这个设计不大舒服 (很容易出现OOM 等等原因)\nJDK 1.8 将 方法区 的实现从 永久代 改成了 元空间MetaSpace. (从 -XX:MaxPermSize 变成 -XX:MetaspaceSize)\n这里最大的区别在于, Metaspace 使用的是 直接内存(本地内存 Native Memory)\n整个永久代有一个 JVM 本身设置固定大小上线，无法进行调整，而元空间使用的是直接内存，受本机可用内存的限制，并且永远不会得到java.lang.OutOfMemoryError。你可以使用 -XX：MaxMetaspaceSize 标志设置最大元空间大小，默认值为 unlimited，这意味着它只受系统内存的限制。-XX：MetaspaceSize 调整标志定义元空间的初始大小如果未指定此标志，则 Metaspace 将根据运行时的应用程序需求动态地重新调整大小。\n运行时常量池: Runtime Constant Pool, 是方法区的一部分. 运行时常量池是方法区的一部分。Class 文件中除了有类的版本、字段、方法、接口等描述信息外，还有常量池信息（用于存放编译期生成的各种字面量和符号引用）\n既然运行时常量池时方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出 OutOfMemoryError 异常。\nJDK1.7及之后版本的 JVM 已经将运行时常量池从方法区中移了出来，在 Java 堆（Heap）中开辟了一块区域存放运行时常量池。\n堆  自动内存管理根本上解决了: 自动给对象分配内存 + 自动回收分配给对象的内存\n Java 虚拟机所管理的内存中最大的一块，Java 堆是所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数组都在这里分配内存。\nJava 堆是垃圾收集器管理的主要区域，因此也被称作GC堆（Garbage Collected Heap）.\n 弱分代假说(Weak Generational Hypothisis): 绝大多数对象都是朝生夕灭 强分代假说(Strong Gernerational Hypothisis): 熬过越多次垃圾回收过程的对象就越难以消亡  堆的分布 从垃圾回收的角度，由于现在收集器基本都采用分代垃圾收集算法，所以Java堆还可以细分为：新生代和老年代：再细致一点有：Eden空间、From Survivor、To Survivor空间等。进一步划分的目的是更好地回收内存，或者更快地分配内存.\n注意: 垃圾回收会应为GC收集器、算法、配置不同而不同\u0026hellip;只能谈个大概\nGC 词汇 GC 分类:\n针对HotSpot VM的实现，它里面的GC其实准确分类只有两大种：\nPartial GC：并不收集整个GC堆的模式 Young GC：只收集young gen的GC、Minor GC Old GC：只收集old gen的GC。只有CMS的concurrent collection是这个模式 Mixed GC：收集整个young gen以及部分old gen的GC。只有G1有这个模式 Full GC：收集整个堆，包括young gen、old gen、perm gen/metaspace（如果存在的话）等所有部分的模式。\nMajor GC通常是跟full GC是等价的，收集整个GC堆。但因为HotSpot VM发展了这么多年，外界对各种名词的解读已经完全混乱了，当有人说“major GC”的时候一定要问清楚他想要指的是上面的full GC还是old GC。\n我们只要关注: YGC/FGC 基本可以解决问题.\nTODO/作业:\nserver 和 executor 分别用了什么垃圾收集器? 基于什么垃圾收集理论? 什么 GC 算法? 优缺点是啥子  一般性的GC流程 (GC收集器、配置、GC算法不同而不同)\n新生代（Young Generation）：大多数对象在新生代中被创建，其中很多对象的生命周期很短。每次新生代的垃圾回收（又称Minor GC、Young GC）后只有少量对象存活(绝大多数对象都是朝生夕灭)，所以选用复制算法，只需要少量的复制成本就可以完成回收。\n新生代内又分三个区：一个Eden区，两个Survivor区，大部分对象在Eden区中生成。当Eden区满时，还存活的对象将被复制到两个Survivor区（中的一个）。当这个Survivor区满时，此区的存活且不满足“晋升”条件的对象将被复制到另外一个Survivor区。对象每经历一次Minor GC，年龄加1，达到“晋升年龄阈值”后，被放到老年代，这个过程也称为“晋升”。显然，“晋升年龄阈值”的大小直接影响着对象在新生代中的停留时间，在Serial和ParNew GC两种回收器中，“晋升年龄阈值”通过参数MaxTenuringThreshold设定，默认值为15。 Survivor的存在意义，就是减少被送到老年代的对象，进而减少Full GC的发生，Survivor的预筛选保证，只有经历16次Minor GC还能在新生代中存活的对象，才会被送到老年代。 但这也不是一定的，对于一些较大的对象 ( 即需要分配一块较大的连续内存空间 ) 则是直接进入到老年代。\n老年代（Old Generation）：在新生代中经历了N次垃圾回收后仍然存活的对象，就会被放到年老代，该区域中对象存活率高。老年代的垃圾回收（又称Major GC）通常使用“标记-清理”或“标记-整理”算法。整堆包括新生代和老年代的垃圾回收称为Full GC（HotSpot VM里，除了CMS之外，其它能收集老年代的GC都会同时收集整个GC堆，包括新生代）。\n一般性的 YGC/FGC YGC的时机:\nedn空间不足\nFGC的时机：\n1.old空间不足；\n2.perm空间不足；(1.8 为 metaspace)\n3.显示调用System.gc() ，包括RMI等的定时触发;\n4.YGC时的悲观策略；\n5.dump live的内存信息时(jmap –dump:live)。\n对YGC的 触发时机，相当的显而易见，就是eden空间不足， 这时候就肯定会触发ygc\n对于FGC的触发时机， old空间不足， 和perm的空间不足， 调用system.gc()这几个都比较显而易见，就是在这种情况下， 一般都会触发GC。\n最复杂的是所谓的悲观策略，它触发的机制是在首先会计算之前晋升的平均大小，也就是从新生代，通过ygc变成新生代的平均大小，然后如果旧生代剩余的空间小于晋升大小，那么就会触发一次FullGC。考虑的策略是， 从平均和长远的情况来看，下次晋升空间不够的可能性非常大， 与其等到那时候在fullGC 不如悲观的认为下次肯定会触发FullGC， 直接先执行一次FullGC。而且从实际使用过程中来看， 也达到了比较稳定的效果。\n堆内存的具体分布 默认的，新生代 ( Young ) 与老年代 ( Old ) 的比例的值为 1:2 ( 该值可以通过参数 –XX:NewRatio 来指定 )，即：新生代 ( Young ) = 1\u0026frasl;3 的堆空间大小。老年代 ( Old ) = 2\u0026frasl;3 的堆空间大小。其中，新生代 ( Young ) 被细分为 Eden 和 两个 Survivor 区域，这两个 Survivor 区域分别被命名为 from 和 to，以示区分。 默认的，Edem : from : to = 8 : 1 : 1 ( 可以通过参数 –XX:SurvivorRatio 来设定 )，即： Eden = 8\u0026frasl;10 的新生代空间大小，from = to = 1\u0026frasl;10 的新生代空间大小。 JVM 每次只会使用 Eden 和其中的一块 Survivor 区域来为对象服务，所以无论什么时候，总是有一块 Survivor 区域是空闲着的。 因此，新生代实际可用的内存空间为 9\u0026frasl;10 ( 即90% )的新生代空间。 From Survivor区域与To Survivor区域是交替切换空间，在同一时间内两者中只有一个不为空\n–XX:SurvivorRatio 两个 Survivor区 和 eden区 的比值, 默认 8 我们未指定 survivor : eden = 2 : 8 –XX:NewRatio 新生代和老年代的比值, 默认 4 新/老 = 1/4 -XX:MaxTenuringThreshold 晋升年龄最大阈值，默认15。在新生代中对象存活次数(经过YGC的次数)后仍然存活，就会晋升到老年代。每经过一次YGC，年龄加1，当survivor区的对象年龄达到TenuringThreshold时，表示该对象是长存活对象，就会直接晋升到老年代。 -XX:TargetSurvivorRatio 设定survivor区的目标使用率。默认50，即survivor区对象目标使用率为50%。 JVM会将每个对象的年龄信息、各个年龄段对象的总大小记录在“age table”表中。基于“age table”、survivor区大小、survivor区目标使用率（-XX:TargetSurvivorRatio）、晋升年龄阈值（-XX:MaxTenuringThreshold），JVM会动态的计算tenuring threshold的值。一旦对象年龄达到了tenuring threshold就会晋升到老年代。 为什么要动态的计算tenuring threshold的值呢？假设有很多年龄还未达到TenuringThreshold的对象依旧停留在survivor区，这样不利于新对象从eden晋升到survivor。因此设置survivor区的目标使用率，当使用率达到时重新调整TenuringThreshold值，让对象尽早的去old区。 如果希望跟踪每次新生代GC后，survivor区中对象的年龄分布，可在启动参数上增加-XX:+PrintTenuringDistribution. 最简单的分代式GC策略，按HotSpot VM的serial GC的实现来看，触发条件是：\nyoung GC：当young gen中的eden区分配满的时候触发。注意young GC中有部分存活对象会晋升到old gen，所以young GC后old gen的占用量通常会有所升高。\nfull GC：当准备要触发一次young GC时，如果发现统计数据说之前young GC的平均晋升大小比目前old gen剩余的空间大，则不会触发young GC而是转为触发full GC（因为HotSpot VM的GC里，除了CMS的concurrent collection之外，其它能收集old gen的GC都会同时收集整个GC堆，包括young gen，所以不需要事先触发一次单独的young GC）；\n或者，如果有perm gen的话，要在perm gen分配空间但已经没有足够空间时，也要触发一次full GC；或者System.gc()、heap dump带GC，默认也是触发full GC。HotSpot VM里其它非并发GC的触发条件复杂一些，不过大致的原理与上面说的其实一样。当然也总有例外。Parallel Scavenge（-XX:+UseParallelGC）框架下，默认是在要触发full GC前先执行一次young GC，并且两次GC之间能让应用程序稍微运行一小下，以期降低full GC的暂停时间（因为young GC会尽量清理了young gen的死对象，减少了full GC的工作量）。控制这个行为的VM参数是-XX:+ScavengeBeforeFullGC。这是HotSpot VM里的奇葩嗯。可跳传送门围观：JVM full GC的奇怪现象，求解惑？ - RednaxelaFX 的回答并发GC的触发条件就不太一样。以CMS GC为例，它主要是定时去检查old gen的使用量，当使用量超过了触发比例就会启动一次CMS GC，对old gen做并发收集。\n为什么有两个 Survivor 区 复制算法\n将原有的内存空间划分成两块，每次只使用其中一块，在垃圾回收的时候，将正在使用的内存中的存活对象复制到另一块内存区域中，然后清除正使用过的内存区域，交换两个区域的角色，完成垃圾回收。然后为什么要在新生代中使用复制算法：因为新生代gc比较频繁、对象存活率低，用复制算法在回收时的效率会更高，也不会产生内存碎片。但复制算法的代价就是要将内存折半，为了不浪费过多的内存，就划分了两块相同大小的内存区域survivor from和survivor to。在每次gc后就会把存活对象给复制到另一个survivor上，然后清空Eden和刚使用过的survivor。\n用空间换时间，你可以模拟新生代回收两次的场景。假设现在只有一个s区，第一次，e满了之后，你把活得对象放到s，如果此时只有一个s区，那么当第二次e去满了之后，就没有s区可用了，为了使第二次GC能够进行所以在只有一个s取得情况下你只能，把s区中的或对象复制一遍放到e区，所以如果有一个s区的话，一次新生代GC要复制两次活对象。而在有两个的情况下，这个问题就可以避免了，e区满了之后进行第一次GC，把活的对象放入s0,此时s1区是没被使用的，当第二次GC的时候再把e区中活的对象和s0中活的对象一同放进s1，你有没有发现在一次GC中，两个s区会比一个s区少复制一次\n链接：https://www.zhihu.com/question/44929481/answer/98052014\n链接：https://www.zhihu.com/question/44929481/answer/98016105\n碎片化、为什么有两个survivor https://blog.csdn.net/antony9118/article/details/51425581\n任务:\n查看 inceptor 使用的是什么垃圾回收器 分别是用了什么算法, 有什么好处? CMSInitiatingOccupancyFraction 是啥意思?  直接内存 直接内存并不是虚拟机运行时数据区的一部分，也不是虚拟机规范中定义的内存区域，但是这部分内存也被频繁地使用。而且也可能导致 OutOfMemoryError 异常出现。\nJDK1.4 中新加入的 NIO(New Input/Output) 类，引入了一种基于通道（Channel） 与缓存区（Buffer） 的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆之间来回复制数据。\n本机直接内存的分配不会收到 Java 堆的限制，但是，既然是内存就会受到本机总内存大小以及处理器寻址空间的限制。(-XX:MaxDirectMemorySize)\n常用命令 k8s 上极其方便的玩法 kubectl exec -it xxx jps xx\n如果后面要加 flag 咋办?\nkubectl exec -it inceptor-server-inceptor2-b67857557-jjtjv \u0026ndash; jps -v\n直接输出到物理机 kubectl exec -it inceptor-server-inceptor2-b67857557-jjtjv \u0026ndash; jps -v \u0026gt;\u0026gt; zz.log\njps JVM Process Status Tool, 用于列出正在运行的虚拟机进程. 用于查看pod 内是否存在进程挂掉/验证是否手动添加JVM参数。 inceptor/slipstream 可以配合 grep 查询虚拟机启动时显式指定的JVM参数。显示没有jinfo全，但是够用。\n[root@linux-158-15 ~]# jps -v | more 43 InceptorServer2 -agentpath:/usr/lib/inceptor/bin/libagent.so -XX:MetaspaceSiz e=512m -XX:MaxMetaspaceSize=2g -Djava.net.preferIPv4Stack=true -Dsun.net.inetadd r.ttl=60 -XX:+UseParNewGC -XX:NewRatio=4 -XX:+CMSClassUnloadingEnabled -XX:MinHe apFreeRatio=100 -XX:MaxHeapFreeRatio=100 -XX:CMSMaxAbortablePrecleanTime=1000 -X X:+ExplicitGCInvokesConcurrent -XX:MaxTenuringThreshold=4 -XX:TargetSurvivorRati o=8 -XX:+HeapDumpOnOutOfMemoryError -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOcc upancyFraction=70 -Xms2048m -Xmx8192m -verbose:gc -XX:+PrintGCDetails -XX:+Print GCDateStamps -XX:+PrintGCTimeStamps -Djava.library.path=/usr/lib/hadoop/lib/nati ve -Dspark.akka.threads=8 -Dspark.akka.threads=8 -Dspark.rdd.compress=false -Dsp ark.storage.memoryFraction=0.5 -Dspark.driver.host=linux-158-15 -Dclass.default. serializer= -Dspark.fastdisk.dir=/vdir/mnt/ramdisk/ngmr -Dspark.storage.fastdisk Fraction=0.5 -Dngmr.task.pipeline=false -Dngmr.task.pipeline.start.fraction=0.5 -Dngmr.task.pipeline.task.timeout.ms=-1 -Dspark.local.dir=/vdir/mnt/disk1/hadoop /ng jinfo Configuration Info for Java, 实时查看虚拟机各项参数，涵盖显式和默认等等，多儿全。\njinfo pid (slipstream executor) Attaching to process ID 50, please wait... Debugger attached successfully. Server compiler detected. JVM version is 25.25-b02 Java System Properties: spark.storage.fastdiskFraction = 0.3 java.vendor = Oracle Corporation inceptor.executorID.zkPath = /slipstream2/executorID sun.java.launcher = SUN_STANDARD sun.management.compiler = HotSpot 64-Bit Tiered Compilers sun.nio.ch.bugLevel = ngmr.engine = morphling spark.network.numberOfBuffers = 10240 os.name = Linux ngmr.task.pipeline.task.timeout.ms = -1 sun.boot.class.path = /usr/java/jdk1.8.0_25/jre/lib/resources.jar:/usr/java/jdk1.8.0_25/jre/lib/rt.jar:/usr/java/jdk1.8.0_25/jre/lib/sunrsasign.jar:/usr/java/jdk1.8.0_25/jre/lib/jsse.jar:/usr/java/jdk1.8.0_25/jre/lib/jce.jar:/usr/java/jdk1.8.0_25/jre/lib/charsets.jar:/usr/java/jdk1.8.0_25/jre/lib/jfr.jar:/usr/java/jdk1.8.0_25/jre/classes spark.network.client.numThreads = 0 java.vm.specification.vendor = Oracle Corporation slipstream.metrics.gateway.host = linux-pm-0-37 java.runtime.version = 1.8.0_25-b17 spark.network.server.numThreads = 0 inceptor.log.dir = /var/log/slipstream2 user.name = hive sun.net.inetaddr.ttl = 60 transwarp.io.netty.noKeySetOptimization = true user.language = en sun.boot.library.path = /usr/java/jdk1.8.0_25/jre/lib/amd64 ngmr.task.pipeline.start.fraction = 0.5 spark.fastdisk.dir = /vdir/mnt/ramdisk/ngmr java.version = 1.8.0_25 spark.kerberos.keytabs = /etc/slipstream2/conf/slipstream.keytab user.timezone = Asia/Shanghai java.net.preferIPv4Stack = true spark.rdd.compress = false sun.arch.data.model = 64 java.endorsed.dirs = /usr/java/jdk1.8.0_25/jre/lib/endorsed sun.cpu.isalist = sun.jnu.encoding = UTF-8 file.encoding.pkg = sun.io spark.kerberos.principal = hive/_HOST@TDH file.separator = / java.specification.name = Java Platform API Specification java.class.version = 52.0 user.country = US java.home = /usr/java/jdk1.8.0_25/jre java.vm.info = mixed mode spark.storage.memoryFraction = 0.5 os.version = 3.10.0-693.el7.x86_64 path.separator = : java.vm.version = 25.25-b02 ngmr.task.pipeline = false java.awt.printerjob = sun.print.PSPrinterJob spark.network.server.backlog = 5 sun.io.unicode.encoding = UnicodeLittle awt.toolkit = sun.awt.X11.XToolkit user.home = /home/hive transwarp.io.netty.noUnsafe = true java.specification.vendor = Oracle Corporation spark.shuffle.io.preferDirectBufs = true spark.shuffle.io.numConnectionsPerPeer = 5 java.library.path = /usr/lib/hadoop/lib/native java.vendor.url = http://java.oracle.com/ java.vm.vendor = Oracle Corporation java.runtime.name = Java(TM) SE Runtime Environment sun.java.command = io.transwarp.nucleon.executor.CoarseGrainedExecutorBackend akka.tcp://sparkDriver@linux-pm-0-37:52888/user/CoarseGrainedScheduler 0 linux-pm-0-38 30 java.class.path = /etc/slipstream2/conf:/etc/hdfs1/conf:/etc/yarn1/conf:/etc/hyperbase1/conf::/usr/lib/guardian-plugins/lib/*:/usr/lib/inceptor/lib/HikariCP-2.6.1.jar:/usr/lib/inceptor/lib/JavaEWAH-0.3.2.jar:/usr.......等等 java.vm.specification.name = Java Virtual Machine Specification java.vm.specification.version = 1.8 sun.cpu.endian = little sun.os.patch.level = unknown java.io.tmpdir = /tmp spark.memory.segmentSize = 32768 inceptor.executorID.zkTimeout = 10000 java.vendor.url.bug = http://bugreport.sun.com/bugreport/ transwarp.io.netty.recycler.maxCapacityPerThread = 0 spark.network.client.connectTimeoutSec = 120 spark.network.sendAndReceiveBuffer = 0 inceptor.executorID.zkServer = linux-pm-0-37,linux-pm-0-38,linux-pm-0-40 os.arch = amd64 java.awt.graphicsenv = sun.awt.X11GraphicsEnvironment class.default.serializer = java.ext.dirs = /usr/java/jdk1.8.0_25/jre/lib/ext:/usr/java/packages/lib/ext user.dir = /home/hive inceptor.executorID.zkPort = 2181 spark.local.dir = /vdir/mnt/disk1/hadoop/ngmr/slipstream2,/vdir/mnt/disk2/hadoop/ngmr/slipstream2,/vdir/mnt/disk3/hadoop/ngmr/slipstream2,/vdir/mnt/disk4/hadoop/ngmr/slipstream2,/vdir/mnt/disk5/hadoop/ngmr/slipstream2 line.separator = java.vm.name = Java HotSpot(TM) 64-Bit Server VM java.security.auth.login.config = /etc/slipstream2/conf/jaas.conf inceptor.authentication = kerberos file.encoding = UTF-8 java.specification.version = 1.8 spark.akka.threads = 8 inceptor.log.file = inceptor-executor.log VM Flags: Non-default VM flags: -XX:CICompilerCount=15 -XX:+CMSClassUnloadingEnabled -XX:CMSInitiatingOccupancyFraction=55 -XX:CMSMaxAbortablePrecleanTime=1000 -XX:+ExplicitGCInvokesConcurrent -XX:+HeapDumpOnOutOfMemoryError -XX:InitialHeapSize=33554432000 -XX:InitialTenuringThreshold=4 -XX:MaxDirectMemorySize=34359738368 -XX:MaxHeapFreeRatio=100 -XX:MaxHeapSize=33554432000 -XX:MaxMetaspaceSize=268435456 -XX:MaxNewSize=6710886400 -XX:MaxTenuringThreshold=4 -XX:MetaspaceSize=268435456 -XX:MinHeapDeltaBytes=196608 -XX:MinHeapFreeRatio=99 -XX:NewRatio=4 -XX:NewSize=6710886400 -XX:OldPLABSize=16 -XX:OldSize=26843545600 -XX:+PrintGC -XX:+PrintGCDateStamps -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:TargetSurvivorRatio=8 -XX:+UseCompressedClassPointers -XX:+UseCompressedOops -XX:+UseConcMarkSweepGC -XX:+UseParNewGC Command line: -agentpath:/usr/lib/inceptor/bin/libagent.so -Dsun.net.inetaddr.ttl=60 -Djava.net.preferIPv4Stack=true -Dspark.akka.threads=8 -Dspark.rdd.compress=false -Dspark.storage.memoryFraction=0.5 -Dclass.default.serializer= -Dspark.fastdisk.dir=/vdir/mnt/ramdisk/ngmr -Dspark.storage.fastdiskFraction=0.3 -Dngmr.task.pipeline=false -Dngmr.task.pipeline.start.fraction=0.5 -Dngmr.task.pipeline.task.timeout.ms=-1 -verbose:gc -Xloggc:/var/log/slipstream2/inceptor-executor.gc.log -XX:+PrintGCDetails -XX:+PrintGCTimeStamps -XX:+PrintGCDateStamps -Dspark.local.dir=/vdir/mnt/disk1/hadoop/ngmr/slipstream2,/vdir/mnt/disk2/hadoop/ngmr/slipstream2,/vdir/mnt/disk3/hadoop/ngmr/slipstream2,/vdir/mnt/disk4/hadoop/ngmr/slipstream2,/vdir/mnt/disk5/hadoop/ngmr/slipstream2 -XX:MetaspaceSize=256m -XX:MaxMetaspaceSize=256m -Djava.library.path=/usr/lib/hadoop/lib/native -Dinceptor.executorID.zkPath=/slipstream2/executorID -Dinceptor.executorID.zkServer=linux-pm-0-37,linux-pm-0-38,linux-pm-0-40 -Dinceptor.executorID.zkPort=2181 -Dinceptor.executorID.zkTimeout=10000 -XX:MaxDirectMemorySize=32G -Xms32000m -Xmx32000m -XX:+UseParNewGC -XX:NewRatio=4 -XX:+CMSClassUnloadingEnabled -XX:MinHeapFreeRatio=100 -XX:MaxHeapFreeRatio=100 -XX:CMSMaxAbortablePrecleanTime=1000 -XX:+ExplicitGCInvokesConcurrent -XX:MaxTenuringThreshold=4 -XX:TargetSurvivorRatio=8 -XX:+HeapDumpOnOutOfMemoryError -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOccupancyFraction=55 -Dinceptor.log.dir=/var/log/slipstream2 -Dinceptor.log.file=inceptor-executor.log -Dinceptor.authentication=kerberos -Dspark.kerberos.keytabs=/etc/slipstream2/conf/slipstream.keytab -Dspark.kerberos.principal=hive/_HOST@TDH -Dngmr.engine=morphling -Dspark.network.sendAndReceiveBuffer=0 -Dspark.network.numberOfBuffers=10240 -Dspark.memory.segmentSize=32768 -Dspark.network.server.numThreads=0 -Dspark.network.client.numThreads=0 -Dspark.network.client.connectTimeoutSec=120 -Dspark.shuffle.io.preferDirectBufs=true -Dspark.shuffle.io.numConnectionsPerPeer=5 -Dspark.network.server.backlog=5 -Dslipstream.metrics.gateway.host=linux-pm-0-37 -Djava.security.auth.login.config=/etc/slipstream2/conf/jaas.conf https://www.cnblogs.com/redcreen/archive/2011/05/04/2037057.html\njstat https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jstat.html\n-gc：监视 JAVA 堆情况，常用查看 gc 容量情况的工具\n-gcutil：主要关注百分比信息\n-gccause：和百分比输出一样，多一个上次垃圾收集产生原因 建议使用 -gccause 收集 GC 信息！！！\nLGCC：Cause of last Garbage Collection GCC：Cause of current Garbage Collection YGC ：对新生代堆进行GC。频率比较高，因为大部分对象的存活寿命较短，在新生代里被回收。性能耗费较小。 FGC ：全堆范围的GC。默认堆空间使用到达80%(可调整)的时候会触发FGC。\n[root@linux-158-15 ~]# jstat -gccause 43 2 5 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT LGCC GCC 20.61 0.00 56.14 3.41 98.85 98.17 32 2.696 5 7.225 9.921 Allocation Failure No GC 20.61 0.00 56.14 3.41 98.85 98.17 32 2.696 5 7.225 9.921 Allocation Failure No GC 20.61 0.00 56.14 3.41 98.85 98.17 32 2.696 5 7.225 9.921 Allocation Failure No GC 20.61 0.00 56.14 3.41 98.85 98.17 32 2.696 5 7.225 9.921 Allocation Failure No GC 20.61 0.00 56.14 3.41 98.85 98.17 32 2.696 5 7.225 9.921 Allocation Failure No GC 以上表明该 inceptor server 新生代Eden区（E）使用了 56% 的空间，两个Survivor 区（Survivor0、Survivor1），老年代（O) 和 元空间（M），程序运行以来发生了 32 次 Minor GC（YGC Young GC），总耗时 2.6 s，发生 Full GC （FGC）5次，总耗时 7s，上次GC（LGCC） 是因为 Allocation Failure （Allocation Failure： 表明本次引起GC的原因是因为在年轻代中没有足够的空间能够存储新的数据了），现在没有在GC （GCC）\nps：方法区 P (或永久代)，用来存放class，Method等元数据信息，但在JDK1.8已经没有了，取而代之的是MetaSpace(元空间)，元空间不在虚拟机里面，而是直接使用本地内存。\n为什么要用元空间代替永久代？ (1) 类以及方法的信息比较难确定其大小，因此对于永久代的指定比较困难，太小容易导致永久代溢出，太大容易导致老年代溢出。 (2) 永久代会给GC带来不需要的复杂度，并且回收效率偏低。 (3) Oracle可能会将HotSpot和Jrockit合二为一。\nCCS: Compressed class space utilization as a percentage.\nYGC 和 Survivor ^C[root@linux-pm-158-51 ~]# jstat -gcutil 47 5s S0 S1 E O M CCS YGC YGCT FGC FGCT GCT 0.00 19.66 54.19 27.52 98.97 97.97 39 1.932 0 0.000 1.932 0.00 19.66 61.45 27.52 98.97 97.97 39 1.932 0 0.000 1.932 0.00 19.66 74.16 27.52 98.97 97.97 39 1.932 0 0.000 1.932 52.19 0.00 30.43 27.94 98.87 98.07 40 1.972 0 0.000 1.972 52.19 0.00 63.37 27.94 98.87 98.07 40 1.972 0 0.000 1.972 52.19 0.00 67.65 27.94 98.87 98.07 40 1.972 0 0.000 1.972 52.19 0.00 83.11 27.94 98.87 98.07 40 1.972 0 0.000 1.972 0.00 63.95 14.55 28.95 98.87 98.15 41 2.021 0 0.000 2.021 81.82 0.00 7.30 30.05 98.83 98.19 42 2.098 0 0.000 2.098 81.82 0.00 44.98 30.05 98.83 98.19 42 2.098 0 0.000 2.098 81.82 0.00 69.58 30.05 98.83 98.19 42 2.098 0 0.000 2.098 81.82 0.00 69.73 30.05 98.83 98.19 42 2.098 0 0.000 2.098 0.00 56.05 17.56 31.32 98.90 98.19 43 2.137 0 0.000 2.137 0.00 56.05 37.69 31.32 98.90 98.19 43 2.137 0 0.000 2.137 44.39 0.00 40.69 32.05 98.95 98.19 44 2.222 0 0.000 2.222 44.39 0.00 90.69 32.05 98.95 98.19 44 2.222 0 0.000 2.222 0.00 44.85 19.95 32.76 99.01 98.20 45 2.308 0 0.000 2.308 0.00 44.85 21.26 32.76 99.01 98.20 45 2.308 0 0.000 2.308 0.00 44.85 33.22 32.76 99.01 98.20 45 2.308 0 0.000 2.308 0.00 29.63 43.46 33.68 98.91 98.20 47 2.453 0 0.000 2.453 24.94 0.00 93.40 34.12 98.92 98.20 48 2.549 0 0.000 2.549 24.94 0.00 95.36 34.12 98.92 98.20 48 2.549 0 0.000 2.549 24.94 0.00 96.11 34.12 98.92 98.20 48 2.549 0 0.000 2.549 S0C: Current survivor space 0 capacity (kB).\nS1C: Current survivor space 1 capacity (kB).\nS0U: Survivor space 0 utilization (kB).\nS1U: Survivor space 1 utilization (kB).\nEC: Current eden space capacity (kB).\nEU: Eden space utilization (kB).\nOC: Current old space capacity (kB).\nOU: Old space utilization (kB).\nMC: Metaspace capacity (kB).\nMU: Metacspace utilization (kB).\nCCSC: Compressed class space capacity (kB).\nCCSU: Compressed class space used (kB).\nYGC: Number of young generation garbage collection events.\nYGCT: Young generation garbage collection time.\nFGC: Number of full GC events.\nFGCT: Full garbage collection time.\nGCT: Total garbage collection time.\nThoughts https://www.oracle.com/technetwork/java/tuning-139912.html\n-XX:TargetSurvivorRatio=8 并没有生效(还好还好), but why?\nageTable.cpp\njmap Memory Map for Java, 用于生成堆转储快照\njmap -heap 47\n显示堆中对象统计信息，包括类、实例数量、合计容量 jmap -histo:live ${JAVA_PID} 【一般简称为jmap（统计信息）】相关效果： 触发一次常规full gc jmap -dump:live,format=b,file=${FILE_PATH} ${JAVA_PID} 【一般简称为heapdump】 相关效果： 触发一次常规full gc，将所有live对象写入文件。 操作及注意事项： a. 由于live对象总大小最大可能达到堆大小(-Xmx指定)，甚至由于存储格式问题达到更大，注意存储文件的磁盘可用空间。 b. 一般可先使用histo分析一下活对象总大小，以此估计文件大小。 c. 网络传输该文件强烈建议先采用常见压缩.tar.gz等，压缩率可达10倍。 ps: 持续 FGC 可能出现 Unable to open socket file 的错误，因为当前Java进程一直在持续的GC，而在GC期间java进程是不响应外部jmap请求，建议一顿猛打，无间隔持续地尝试jmap命令一定时间（不超过2分钟），一般在其中可以有概率成功打出jmap。\npps: 由 live 引起的 FGC 可以在GC日志看到:Heap Inspection Initiated GC 标志\njstack Stack Trace for Java, 生成虚拟机当前时刻的线程快照，线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的 目的通常是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间挂 起等，都是导致线程长时间停顿的常见原因。线程出现停顿时通过jstack来查看各个线程的调用堆栈， 就可以获知没有响应的线程到底在后台做些什么事情，或者等待着什么资源。\n一般存在 incepto job 卡死，等情况需要用到，隔 x 秒打几个。\njstack pid 可尝试“su hive”，再打jstack信息。 sudo -u hive /usr/java/latest/bin/jstack {PID} Slipstream 常用分析 (待续) -XX:CMSInitiatingOccupancyFraction=70 CMS垃圾收集器，当老年代达到70%时，触发CMS垃圾回收。\n作业 阅读:\n常见OOM报错 https://my.oschina.net/huyuBlog/blog/1788473\nRef 《深入理解JVM虚拟机》\n深入理解JVM虚拟机 笔记 https://www.cnblogs.com/chanshuyi/p/jvm_serial_00_why_learn_jvm.html\n《Java 虚拟机规范》\n总结图 https://www.zhihu.com/question/29833675\n为什么 32 位 JVM 最多使用 4G 内存.\nhttps://xiaozhuanlan.com/topic/1847690325#section153permgenmetaspace\n分代理论 https://blog.csdn.net/Muyundefeng/article/details/72667863\n为什么有两个 survivor 区 https://blog.csdn.net/antony9118/article/details/51425581\nJVM 参数解析 https://www.cnblogs.com/redcreen/archive/2011/05/04/2037057.html\nGC分代收集 https://juejin.im/post/5b6b986c6fb9a04fd1603f4a\nGC 分类 作者：RednaxelaFX 链接：https://www.zhihu.com/question/41922036/answer/93079526\n","href":"/java/jvm%E5%8E%9F%E7%90%86%E5%85%A5%E9%97%A8/","title":"JVM原理入门"},{"content":" Java 基础运维工具使用   jps JVM Process Status Tool, 用于列出正在运行的虚拟机进程. 用于查看pod 内是否存在进程挂掉/验证是否手动添加JVM参数。 inceptor/slipstream 可以配合 grep 查询虚拟机启动时显式指定的JVM参数。显示没有jinfo全，但是够用。\n[root@linux-158-15 ~]# jps -v | more 43 InceptorServer2 -agentpath:/usr/lib/inceptor/bin/libagent.so -XX:MetaspaceSiz e=512m -XX:MaxMetaspaceSize=2g -Djava.net.preferIPv4Stack=true -Dsun.net.inetadd r.ttl=60 -XX:+UseParNewGC -XX:NewRatio=4 -XX:+CMSClassUnloadingEnabled -XX:MinHe apFreeRatio=100 -XX:MaxHeapFreeRatio=100 -XX:CMSMaxAbortablePrecleanTime=1000 -X X:+ExplicitGCInvokesConcurrent -XX:MaxTenuringThreshold=4 -XX:TargetSurvivorRati o=8 -XX:+HeapDumpOnOutOfMemoryError -XX:+UseConcMarkSweepGC -XX:CMSInitiatingOcc upancyFraction=70 -Xms2048m -Xmx8192m -verbose:gc -XX:+PrintGCDetails -XX:+Print GCDateStamps -XX:+PrintGCTimeStamps -Djava.library.path=/usr/lib/hadoop/lib/nati ve -Dspark.akka.threads=8 -Dspark.akka.threads=8 -Dspark.rdd.compress=false -Dsp ark.storage.memoryFraction=0.5 -Dspark.driver.host=linux-158-15 -Dclass.default. serializer= -Dspark.fastdisk.dir=/vdir/mnt/ramdisk/ngmr -Dspark.storage.fastdisk Fraction=0.5 -Dngmr.task.pipeline=false -Dngmr.task.pipeline.start.fraction=0.5 -Dngmr.task.pipeline.task.timeout.ms=-1 -Dspark.local.dir=/vdir/mnt/disk1/hadoop /ng jstat JVM Statistics Monitoring Tool, 用于监视虚拟机各种运行状态信息。\njstat [ option vmid [interval[s|ms] [count]] ] 每200毫秒查询一次 进程43 的垃圾收集情况，一共查询5次 jstat -gc 43 200 5 2 秒 jstat -gc 43 2s 5 jstat 常用选项 https://docs.oracle.com/javase/8/docs/technotes/tools/unix/jstat.html\n-gc：监视 JAVA 堆情况，常用查看 gc 容量情况的工具\n-gcutil：主要关注百分比信息\n-gccause：和百分比输出一样，多一个上次垃圾收集产生原因 建议使用 -gccause 收集 GC 信息！！！\nLGCC：Cause of last Garbage Collection GCC：Cause of current Garbage Collection YGC ：对新生代堆进行GC。频率比较高，因为大部分对象的存活寿命较短，在新生代里被回收。性能耗费较小。 FGC ：全堆范围的GC。默认堆空间使用到达80%(可调整)的时候会触发FGC。\n[root@linux-158-15 ~]# jstat -gccause 43 2 5 S0 S1 E O M CCS YGC YGCT FGC FGCT GCT LGCC GCC 20.61 0.00 56.14 3.41 98.85 98.17 32 2.696 5 7.225 9.921 Allocation Failure No GC 20.61 0.00 56.14 3.41 98.85 98.17 32 2.696 5 7.225 9.921 Allocation Failure No GC 20.61 0.00 56.14 3.41 98.85 98.17 32 2.696 5 7.225 9.921 Allocation Failure No GC 20.61 0.00 56.14 3.41 98.85 98.17 32 2.696 5 7.225 9.921 Allocation Failure No GC 20.61 0.00 56.14 3.41 98.85 98.17 32 2.696 5 7.225 9.921 Allocation Failure No GC 以上表明该 inceptor server 新生代Eden区（E）使用了 56% 的空间，两个Survivor 区（Survivor0、Survivor1），老年代（O) 和 元空间（M），程序运行以来发生了 32 次 Minor GC（YGC Young GC），总耗时 2.6 s，发生 Full GC （FGC）5次，总耗时 7s，上次GC（LGCC） 是因为 Allocation Failure （Allocation Failure： 表明本次引起GC的原因是因为在年轻代中没有足够的空间能够存储新的数据了），现在没有在GC （GCC）\nps：方法区 P (或永久代)，用来存放class，Method等元数据信息，但在JDK1.8已经没有了，取而代之的是MetaSpace(元空间)，元空间不在虚拟机里面，而是直接使用本地内存。\n为什么要用元空间代替永久代？ (1) 类以及方法的信息比较难确定其大小，因此对于永久代的指定比较困难，太小容易导致永久代溢出，太大容易导致老年代溢出。 (2) 永久代会给GC带来不需要的复杂度，并且回收效率偏低。 (3) Oracle可能会将HotSpot和Jrockit合二为一。\nYGC FGC 触发时机 YGC的时机:\nedn空间不足\nFGC的时机：\n1.old空间不足；\n2.perm空间不足；\n3.显示调用System.gc() ，包括RMI等的定时触发;\n4.YGC时的悲观策略；\n5.dump live的内存信息时(jmap –dump:live)。\n对YGC的 触发时机，相当的显而易见，就是eden空间不足， 这时候就肯定会触发ygc\n对于FGC的触发时机， old空间不足， 和perm的空间不足， 调用system.gc()这几个都比较显而易见，就是在这种情况下， 一般都会触发GC。\njinfo Configuration Info for Java, 实时查看虚拟机各项参数，涵盖显式和默认等等，多儿全。\njinfo pid https://www.cnblogs.com/redcreen/archive/2011/05/04/2037057.html\njmap Memory Map for Java, 用于生成堆转储快照\njmap -heap 47\n显示堆中对象统计信息，包括类、实例数量、合计容量 jmap -histo:live ${JAVA_PID} 【一般简称为jmap（统计信息）】相关效果： 触发一次常规full gc jmap -dump:live,format=b,file=${FILE_PATH} ${JAVA_PID} 【一般简称为heapdump】 相关效果： 触发一次常规full gc，将所有live对象写入文件。 操作及注意事项： a. 由于live对象总大小最大可能达到堆大小(-Xmx指定)，甚至由于存储格式问题达到更大，注意存储文件的磁盘可用空间。 b. 一般可先使用histo分析一下活对象总大小，以此估计文件大小。 c. 网络传输该文件强烈建议先采用常见压缩.tar.gz等，压缩率可达10倍。 ps: 持续 FGC 可能出现 Unable to open socket file 的错误，因为当前Java进程一直在持续的GC，而在GC期间java进程是不响应外部jmap请求，建议一顿猛打，无间隔持续地尝试jmap命令一定时间（不超过2分钟），一般在其中可以有概率成功打出jmap。\npps: 由 live 引起的 FGC 可以在GC日志看到:Heap Inspection Initiated GC 标志\njstack Stack Trace for Java, 生成虚拟机当前时刻的线程快照，线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合，生成线程快照的 目的通常是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间挂 起等，都是导致线程长时间停顿的常见原因。线程出现停顿时通过jstack来查看各个线程的调用堆栈， 就可以获知没有响应的线程到底在后台做些什么事情，或者等待着什么资源。\n一般存在 incepto job 卡死，等情况需要用到，隔 x 秒打几个。\njstack pid 可尝试“su hive”，再打jstack信息。 sudo -u hive /usr/java/latest/bin/jstack {PID} Ref jstat 含义：https://docs.oracle.com/javase/7/docs/technotes/tools/share/jstat.html\njmap 姿势：http://172.16.1.168:8090/pages/viewpage.action?pageId=18684230\njstack 姿势：http://172.16.1.168:8090/pages/viewpage.action?pageId=18683344\n","href":"/java/jvm%E5%B7%A5%E5%85%B7%E4%BD%BF%E7%94%A8/","title":"JVM工具使用"},{"content":"","href":"/flink/","title":"Flinks"},{"content":" Flink 源码阅读之任务提交基本流程 org.apache.flink.runtime.blob.BlobServer#run java.net.ServerSocket#accept\nBlobServer.run\n涉及的类:\norg.apache.flink.client.cli.CliFrontend org.apache.flink.client.ClientUtils org.apache.flink.streaming.examples.wordcount.WordCount\norg.apache.flink.runtime.blob.BlobServer#run\norg.apache.flink.runtime.taskexecutor.TaskExecutor#submitTask\norg.apache.flink.runtime.deployment.TaskDeploymentDescriptor\n流程准备 以远程调试模式运行 org.apache.flink.client.cli.CliFrontend\norg.apache.flink.runtime.entrypoint.StandaloneSessionClusterEntrypoint\norg.apache.flink.runtime.taskexecutor.TaskManagerRunner\n使用 ./flink 提交 WordCount.jar, 查看整个任务的流转过程\norg.apache.flink.client.program.PackagedProgram#callMainMethod java.lang.reflect.Method#invoke\norg.apache.flink.streaming.api.environment.StreamContextEnvironment#execute\norg.apache.flink.streaming.api.graph.StreamGraphGenerator#generate\norg.apache.flink.streaming.api.graph.StreamGraphGenerator#transform\norg.apache.flink.streaming.api.environment.StreamExecutionEnvironment#executeAsync(org.apache.flink.streaming.api.graph.StreamGraph)\norg.apache.flink.core.execution.JobListener#onJobSubmitted\norg.apache.flink.client.program.rest.RestClusterClient#submitJob\nJM\norg.apache.flink.runtime.dispatcher.Dispatcher#submitJob log.info(\u0026ldquo;Received JobGraph submission {} ({}).\u0026rdquo;, jobGraph.getJobID(), jobGraph.getName());\norg.apache.flink.runtime.dispatcher.Dispatcher#runJob\norg.apache.flink.runtime.dispatcher.Dispatcher#createJobManagerRunner\nflink-rest-server-netty-worker-thread org.apache.flink.runtime.rest.handler.AbstractRestHandler#handleRequest org.apache.flink.runtime.rest.handler.AbstractRestHandler#respondToRequest\norg.apache.flink.runtime.rpc.akka.AkkaRpcActor#handleRpcMessage\nJM org.apache.flink.runtime.blob.BlobServer#run java.net.ServerSocket#accept\norg.apache.flink.streaming.api.environment.StreamContextEnvironment#execute\nJob 发到 JM 后\norg.apache.flink.runtime.dispatcher.Dispatcher#runJob\norg.apache.flink.runtime.jobmaster.JobMaster#offerSlots\nScheduler 调度 生成 StreamGraph org.apache.flink.runtime.executiongraph.Execution\n发给 TM RemoteRpcInvocation(submitTask(TaskDeploymentDescriptor, JobMasterId, Time))\norg.apache.flink.runtime.taskexecutor.TaskExecutor#submitTask\nsubmitTask 方法 new 一个 Task\nTM 去 Blobserver 拿jar https://juejin.im/post/5e80ae51518825736d278248\norg.apache.flink.runtime.taskmanager.Task#startTaskThread\nInputGateDeploymentDescriptor 是什么\nWhat‘s more 通过基本的执行流程我们可以衍生出很多精进的知识去了解.\n 如何生成 Job 链 RPC 具体实现, 都是干嘛的 Checkpoint机制 Task 容错 与Kafka 的对接等等  ","href":"/flink/flink%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%B9%8B%E4%BB%BB%E5%8A%A1%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B/","title":"Flink源码阅读之任务提交流程"},{"content":" Flink源码阅读之启动流程  本文分析了 Flink standalone/yarn 的启动流程\n 先看启动脚本 start-cluster.sh ## 读取默认 config 配置文件 . \u0026#34;$bin\u0026#34;/config.sh # Start the JobManager instance(s) ## 用来定制 shell 环境 -s 开启某个选项 nocasematch 忽略大小写 shopt -s nocasematch ## 支持高可用模式启动 if [[ $HIGH_AVAILABILITY == \u0026#34;zookeeper\u0026#34; ]]; then # HA Mode readMasters echo \u0026#34;Starting HA cluster with ${#MASTERS[@]}masters.\u0026#34; for ((i=0;i\u0026lt;${#MASTERS[@]};++i)); do master=${MASTERS[i]} webuiport=${WEBUIPORTS[i]} if [ ${MASTERS_ALL_LOCALHOST} = true ] ; then \u0026#34;${FLINK_BIN_DIR}\u0026#34;/jobmanager.sh start \u0026#34;${master}\u0026#34; \u0026#34;${webuiport}\u0026#34; else ssh -n $FLINK_SSH_OPTS $master -- \u0026#34;nohup /bin/bash -l \\\u0026#34;${FLINK_BIN_DIR}/jobmanager.sh\\\u0026#34; start ${master}${webuiport}\u0026amp;\u0026#34; fi done else ## 正常 cluster 模式启动 echo \u0026#34;Starting cluster.\u0026#34; # Start single JobManager on this machine \u0026#34;$FLINK_BIN_DIR\u0026#34;/jobmanager.sh start fi shopt -u nocasematch # Start TaskManager instance(s) TMSlaves start 查看实际启动的 jobmanager.sh # Start/stop a Flink JobManager. ## echo 出脚本的用法，可以学着这种写法 USAGE=\u0026#34;Usage: jobmanager.sh ((start|start-foreground) [host] [webui-port])|stop|stop-all\u0026#34; ## %1 表示第一个变量 STARTSTOP=$1 ## 第二个 HOST=$2 # optional when starting multiple instances ## 第三个 WEBUIPORT=$3 # optional when starting multiple instances ## 如果第一个参数 STARTSTOP 不是以下几种，则返回 USAGE; 学习 if [[ $STARTSTOP != \u0026#34;start\u0026#34; ]] \u0026amp;\u0026amp; [[ $STARTSTOP != \u0026#34;start-foreground\u0026#34; ]] \u0026amp;\u0026amp; [[ $STARTSTOP != \u0026#34;stop\u0026#34; ]] \u0026amp;\u0026amp; [[ $STARTSTOP != \u0026#34;stop-all\u0026#34; ]]; then echo $USAGE exit 1 fi ## 这个命令很少直接在shell命令行中使用，我们一般把它用在shell脚本中，用于取得脚本文件所在目录，然后将当前目录切换过去。 bin=`dirname \u0026#34;$0\u0026#34;` bin=`cd \u0026#34;$bin\u0026#34;; pwd` ## 读取配置文件 . \u0026#34;$bin\u0026#34;/config.sh ## 启动入口，默认 standalonesession ENTRYPOINT=standalonesession if [[ $STARTSTOP == \u0026#34;start\u0026#34; ]] || [[ $STARTSTOP == \u0026#34;start-foreground\u0026#34; ]]; then if [ ! -z \u0026#34;${FLINK_JM_HEAP_MB}\u0026#34; ] \u0026amp;\u0026amp; [ \u0026#34;${FLINK_JM_HEAP}\u0026#34; == 0 ]; then echo \u0026#34;used deprecated key \\`${KEY_JOBM_MEM_MB}\\`, please replace with key \\`${KEY_JOBM_MEM_SIZE}\\`\u0026#34; else flink_jm_heap_bytes=$(parseBytes ${FLINK_JM_HEAP}) FLINK_JM_HEAP_MB=$(getMebiBytes ${flink_jm_heap_bytes}) fi if [[ ! ${FLINK_JM_HEAP_MB} =~ $IS_NUMBER ]] || [[ \u0026#34;${FLINK_JM_HEAP_MB}\u0026#34; -lt \u0026#34;0\u0026#34; ]]; then echo \u0026#34;[ERROR] Configured JobManager memory size is not a valid value. Please set \u0026#39;${KEY_JOBM_MEM_SIZE}\u0026#39; in ${FLINK_CONF_FILE}.\u0026#34; exit 1 fi if [ \u0026#34;${FLINK_JM_HEAP_MB}\u0026#34; -gt \u0026#34;0\u0026#34; ]; then export JVM_ARGS=\u0026#34;$JVM_ARGS-Xms\u0026#34;$FLINK_JM_HEAP_MB\u0026#34;m -Xmx\u0026#34;$FLINK_JM_HEAP_MB\u0026#34;m\u0026#34; fi # Add JobManager-specific JVM options export FLINK_ENV_JAVA_OPTS=\u0026#34;${FLINK_ENV_JAVA_OPTS}${FLINK_ENV_JAVA_OPTS_JM}\u0026#34; # Startup parameters ## 相关参数可以加到这里 args=(\u0026#34;--configDir\u0026#34; \u0026#34;${FLINK_CONF_DIR}\u0026#34; \u0026#34;--executionMode\u0026#34; \u0026#34;cluster\u0026#34;) if [ ! -z $HOST ]; then args+=(\u0026#34;--host\u0026#34;) args+=(\u0026#34;${HOST}\u0026#34;) fi if [ ! -z $WEBUIPORT ]; then args+=(\u0026#34;--webui-port\u0026#34;) args+=(\u0026#34;${WEBUIPORT}\u0026#34;) fi fi if [[ $STARTSTOP == \u0026#34;start-foreground\u0026#34; ]]; then exec \u0026#34;${FLINK_BIN_DIR}\u0026#34;/flink-console.sh $ENTRYPOINT \u0026#34;${args[@]}\u0026#34; else \u0026#34;${FLINK_BIN_DIR}\u0026#34;/flink-daemon.sh $STARTSTOP $ENTRYPOINT \u0026#34;${args[@]}\u0026#34; fi flink 真正的启动类 flink-daemon.sh # Start/stop a Flink daemon. USAGE=\u0026#34;Usage: flink-daemon.sh (start|stop|stop-all) (taskexecutor|zookeeper|historyserver|standalonesession|standalonejob) [args]\u0026#34; STARTSTOP=$1 DAEMON=$2 ARGS=(\u0026#34;${@:3}\u0026#34;) # get remaining arguments as array bin=`dirname \u0026#34;$0\u0026#34;` bin=`cd \u0026#34;$bin\u0026#34;; pwd` . \u0026#34;$bin\u0026#34;/config.sh case $DAEMON in (taskexecutor) ## Task Manager 启动类 CLASS_TO_RUN=org.apache.flink.runtime.taskexecutor.TaskManagerRunner ;; (zookeeper) CLASS_TO_RUN=org.apache.flink.runtime.zookeeper.FlinkZooKeeperQuorumPeer ;; (historyserver) CLASS_TO_RUN=org.apache.flink.runtime.webmonitor.history.HistoryServer ;; ## 默认传滴就是 standalonesession 所以是在这里啦 (standalonesession) CLASS_TO_RUN=org.apache.flink.runtime.entrypoint.StandaloneSessionClusterEntrypoint ;; (standalonejob) CLASS_TO_RUN=org.apache.flink.container.entrypoint.StandaloneJobClusterEntryPoint ;; (*) echo \u0026#34;Unknown daemon \u0026#39;${DAEMON}\u0026#39;. $USAGE.\u0026#34; exit 1 ;; esac if [ \u0026#34;$FLINK_IDENT_STRING\u0026#34; = \u0026#34;\u0026#34; ]; then FLINK_IDENT_STRING=\u0026#34;$USER\u0026#34; fi FLINK_TM_CLASSPATH=`constructFlinkClassPath` pid=$FLINK_PID_DIR/flink-$FLINK_IDENT_STRING-$DAEMON.pid mkdir -p \u0026#34;$FLINK_PID_DIR\u0026#34; # Log files for daemons are indexed from the process ID\u0026#39;s position in the PID # file. The following lock prevents a race condition during daemon startup # when multiple daemons read, index, and write to the PID file concurrently. # The lock is created on the PID directory since a lock file cannot be safely # removed. The daemon is started with the lock closed and the lock remains # active in this script until the script exits. command -v flock \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 if [[ $? -eq 0 ]]; then exec 200\u0026lt;\u0026#34;$FLINK_PID_DIR\u0026#34; flock 200 fi # Ascending ID depending on number of lines in pid file. # This allows us to start multiple daemon of each type. id=$([ -f \u0026#34;$pid\u0026#34; ] \u0026amp;\u0026amp; echo $(wc -l \u0026lt; \u0026#34;$pid\u0026#34;) || echo \u0026#34;0\u0026#34;) FLINK_LOG_PREFIX=\u0026#34;${FLINK_LOG_DIR}/flink-${FLINK_IDENT_STRING}-${DAEMON}-${id}-${HOSTNAME}\u0026#34; log=\u0026#34;${FLINK_LOG_PREFIX}.log\u0026#34; out=\u0026#34;${FLINK_LOG_PREFIX}.out\u0026#34; log_setting=(\u0026#34;-Dlog.file=${log}\u0026#34; \u0026#34;-Dlog4j.configuration=file:${FLINK_CONF_DIR}/log4j.properties\u0026#34; \u0026#34;-Dlogback.configurationFile=file:${FLINK_CONF_DIR}/logback.xml\u0026#34;) JAVA_VERSION=$(${JAVA_RUN} -version 2\u0026gt;\u0026amp;1 | sed \u0026#39;s/.*version \u0026#34;\\(.*\\)\\.\\(.*\\)\\..*\u0026#34;/\\1\\2/; 1q\u0026#39;) # Only set JVM 8 arguments if we have correctly extracted the version if [[ ${JAVA_VERSION} =~ ${IS_NUMBER} ]]; then if [ \u0026#34;$JAVA_VERSION\u0026#34; -lt 18 ]; then JVM_ARGS=\u0026#34;$JVM_ARGS-XX:MaxPermSize=256m\u0026#34; fi fi case $STARTSTOP in (start) # Rotate log files rotateLogFilesWithPrefix \u0026#34;$FLINK_LOG_DIR\u0026#34; \u0026#34;$FLINK_LOG_PREFIX\u0026#34; # Print a warning if daemons are already running on host if [ -f \u0026#34;$pid\u0026#34; ]; then active=() while IFS=\u0026#39;\u0026#39; read -r p || [[ -n \u0026#34;$p\u0026#34; ]]; do kill -0 $p \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 if [ $? -eq 0 ]; then active+=($p) fi done \u0026lt; \u0026#34;${pid}\u0026#34; count=\u0026#34;${#active[@]}\u0026#34; if [ ${count} -gt 0 ]; then echo \u0026#34;[INFO] $countinstance(s) of $DAEMONare already running on $HOSTNAME.\u0026#34; fi fi # Evaluate user options for local variable expansion FLINK_ENV_JAVA_OPTS=$(eval echo ${FLINK_ENV_JAVA_OPTS}) echo \u0026#34;Starting $DAEMONdaemon on host $HOSTNAME.\u0026#34; $JAVA_RUN $JVM_ARGS ${FLINK_ENV_JAVA_OPTS} \u0026#34;${log_setting[@]}\u0026#34; -classpath \u0026#34;`manglePathList \u0026#34;$FLINK_TM_CLASSPATH:$INTERNAL_HADOOP_CLASSPATHS\u0026#34;`\u0026#34; ${CLASS_TO_RUN} \u0026#34;${ARGS[@]}\u0026#34; \u0026gt; \u0026#34;$out\u0026#34; 200\u0026lt;\u0026amp;- 2\u0026gt;\u0026amp;1 \u0026lt; /dev/null \u0026amp; mypid=$! # Add to pid file if successful start if [[ ${mypid} =~ ${IS_NUMBER} ]] \u0026amp;\u0026amp; kill -0 $mypid \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 ; then echo $mypid \u0026gt;\u0026gt; \u0026#34;$pid\u0026#34; else echo \u0026#34;Error starting $DAEMONdaemon.\u0026#34; exit 1 fi ;; (stop) if [ -f \u0026#34;$pid\u0026#34; ]; then # Remove last in pid file to_stop=$(tail -n 1 \u0026#34;$pid\u0026#34;) if [ -z $to_stop ]; then rm \u0026#34;$pid\u0026#34; # If all stopped, clean up pid file echo \u0026#34;No $DAEMONdaemon to stop on host $HOSTNAME.\u0026#34; else sed \\$d \u0026#34;$pid\u0026#34; \u0026gt; \u0026#34;$pid.tmp\u0026#34; # all but last line # If all stopped, clean up pid file [ $(wc -l \u0026lt; \u0026#34;$pid.tmp\u0026#34;) -eq 0 ] \u0026amp;\u0026amp; rm \u0026#34;$pid\u0026#34; \u0026#34;$pid.tmp\u0026#34; || mv \u0026#34;$pid.tmp\u0026#34; \u0026#34;$pid\u0026#34; if kill -0 $to_stop \u0026gt; /dev/null 2\u0026gt;\u0026amp;1; then echo \u0026#34;Stopping $DAEMONdaemon (pid: $to_stop) on host $HOSTNAME.\u0026#34; kill $to_stop else echo \u0026#34;No $DAEMONdaemon (pid: $to_stop) is running anymore on $HOSTNAME.\u0026#34; fi fi else echo \u0026#34;No $DAEMONdaemon to stop on host $HOSTNAME.\u0026#34; fi ;; (stop-all) if [ -f \u0026#34;$pid\u0026#34; ]; then mv \u0026#34;$pid\u0026#34; \u0026#34;${pid}.tmp\u0026#34; while read to_stop; do if kill -0 $to_stop \u0026gt; /dev/null 2\u0026gt;\u0026amp;1; then echo \u0026#34;Stopping $DAEMONdaemon (pid: $to_stop) on host $HOSTNAME.\u0026#34; kill $to_stop else echo \u0026#34;Skipping $DAEMONdaemon (pid: $to_stop), because it is not running anymore on $HOSTNAME.\u0026#34; fi done \u0026lt; \u0026#34;${pid}.tmp\u0026#34; rm \u0026#34;${pid}.tmp\u0026#34; fi ;; (*) echo \u0026#34;Unexpected argument \u0026#39;$STARTSTOP\u0026#39;. $USAGE.\u0026#34; exit 1 ;; esac 终于找到 StandaloneSessionClusterEntrypoint 启动类 啦 通过查看 三 个启动脚本，终于找到了 standalone 的启动类 StandaloneSessionClusterEntrypoint，下面看看源码是怎么实现的\n","href":"/flink/flink%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%B9%8B%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/","title":"Flink源码阅读之启动流程"},{"content":"","href":"/scala/intro/","title":"Intro"},{"content":"","href":"/scala/","title":"Scalas"},{"content":"","href":"/java/intro/","title":"Intro"},{"content":" haha ","href":"/flink/intro/","title":"Intro"},{"content":"","href":"/kafka/","title":"Kafkas"},{"content":" kafka源码解析之 ServerSocketChannel 详解  由于kafka socketServer 使用到了 nio 的 serverSocketChannel, 本文详细解析了 该类的使用方法。 https://blog.csdn.net/kavu1/article/details/53212178\n Kafka 的 kafka.network.Acceptor 负责监听外界 Socket 连接并把请求转发给 kafka.network.Processor，完事后 Processor 负责转发 Socket 的请求和响应，并将其发送到 kafka.network.RequestChannel。\n与java.net.Socket类和java.net.ServerSocket类相对应，NIO也提供了SocketChannel和ServerSocketChannel两种不同的套接字通道实现。这两种新增的通道都支持阻塞和非阻塞两种模式。 低负载、低并发的应用程序可以选择同步阻塞I/O以降低编程复杂度；对于高负载、高并发的网络应用，需要使用NIO的非阻塞模式进行开发。 链接：https://www.jianshu.com/p/5442b04ccff8\n注意, 如果一个 Channel 要注册到 Selector 中, 那么这个 Channel 必须是非阻塞的, 即channel.configureBlocking(false); 因为 Channel 必须要是非阻塞的, 因此 FileChannel 是不能够使用选择器的, 因为 FileChannel 都是阻塞的.\nServerSocketChannel 与 ServerSocket ServerSocketChannel类似于SocketChannel,只不过ServerSocketChannel使用server端.ServerSocketChannel是ServerSocket + Selector的高层 封装.可以通过socket()方法获得与其关联的ServerSocket.\n事实上channel即为socket链接的高层封装,每个channel都绑定在一个socket上,它们息息相关.\nSocketChannel的关闭支持异步关闭(来自InterruptableChannel特性),这与Channel类中指定的异步close操作有关.如果一个线程关闭了某个Socket input,那么同时另一个线程被阻塞在该SocketChannel的read操作中,那么处于阻塞线程中的读取操作将完成,而不读取任何字节且返回-1.如果一个线程关闭了socket output,而同时另一个线程被阻塞在该socketChannel的write操作中,此时阻塞线程将收到AsynchronousClosedException.\nSocketChannel是线程安全的,但是任何时刻只能有一个线程处于read或者write操作(read操作同步readLock,write操作同步writeLock,2个线程可以同时进行read和write;),不过DatagramChannel支持并发的读写.\n参考:http://shift-alt-ctrl.iteye.com/blog/1840409\nNIO 的四种事件    OP_ACCEPT OP_CONNECT OP_WRITE OP_READ        Y Y Y SocketChannel 客户端   Y    ServerSocketChannel 服务端     Y Y SocketChannel 服务端            就绪条件：\nOP_ACCEPT就绪条件： 当收到一个客户端的连接请求时，该操作就绪。这是ServerSocketChannel上唯一有效的操作。 OP_CONNECT就绪条件： 只有客户端SocketChannel会注册该操作，当客户端调用SocketChannel.connect()时，该操作会就绪。 OP_READ就绪条件： 该操作对客户端和服务端的SocketChannel都有效，当OS的读缓冲区中有数据可读时，该操作就绪。 OP_WRITE就绪条件： 该操作对客户端和服务端的SocketChannel都有效，当OS的写缓冲区中有空闲的空间时，该操作就绪。\nAcceptor 与 java.nio.channels.ServerSocketChannel 可以理解为 Acceptor 为了和 processor 通信， 是包装了 一层的 ServerSocketChannel。\n查看 acceptor 的 class 和 run 方法， 发现主要是：\n 通过 new ServerSocketChannel 开启 Socket 服务 注册 OP_ACCEPT 事件，表示该accptor 可以被外界访问，已经开始监听 通过 key.isAcceptable 确认 acceptor 正常，使用 round-robin 轮询将对应的 SocketChannel 发送到 Processor 线程。  Selector不断轮询是否有事件准备好了，如果有事件准备好了则获取事件相应的SelectionKey，进入事件处理\n","href":"/kafka/kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%B9%8Bserversocketchannel/","title":"Kafka源码阅读之ServerSocketChannel"},{"content":" kafka源码解析之性能篇 概念篇 Linux 的 Page Cache 和 Buffer Cache page cache是系统读写磁盘文件时为了提高性能而将一部分文件缓存到内存中。 这种做法虽然提高了磁盘I/O性能，但是也极大的占用了物理内存，特别当系统内存紧张时更容易出现问题。\n也就是说，我们平常向硬盘写文件时，默认异步情况下，并不是直接把文件内容写入到硬盘中才返回的，而是成功拷贝到内核的page cache后就直接返回，所以大多数情况下，硬盘写操作不会是性能瓶颈。写入到内核page cache的pages成为dirty pages，稍后会由内核线程pdflush真正写入到硬盘上。\n从硬盘读取文件时，同样不是直接把硬盘上文件内容读取到用户态内存，而是先拷贝到内核的page cache，然后再“拷贝”到用户态内存，这样用户就可以访问该文件。因为涉及到硬盘操作，所以第一次读取一个文件时，不会有性能提升；不过，如果一个文件已经存在page cache中，再次读取该文件时就可以直接从page cache中命中读取不涉及硬盘操作，这时性能就会有很大提高。\nPage Cache 的构成 page cache中的每个文件都是一棵基数树（radix tree，本质上是多叉搜索树），树的每个节点都是一个页。根据文件内的偏移量就可以快速定位到所在的页，如下图所示。\n原理篇 Kafka为什么不自己管理缓存，而非要用page cache？原因有如下三点：\n JVM中一切皆对象，数据的对象存储会带来所谓object overhead，浪费空间；\n 如果由JVM来管理缓存，会受到GC的影响，并且过大的堆也会拖累GC的效率，降低吞吐量；\n 一旦程序崩溃，自己管理的缓存数据会全部丢失。\n  Kafka三大件（broker、producer、consumer）与page cache的关系可以用下面的简图来表示。\n![page cache](./images/pagecache.jpg）\nproducer生产消息时，会使用pwrite()系统调用【对应到Java NIO中是FileChannel.write() API】按偏移量写入数据，并且都会先写入page cache里。consumer消费消息时，会使用sendfile()系统调用【对应FileChannel.transferTo() API】，零拷贝地将数据从page cache传输到broker的Socket buffer，再通过网络传输。\nhttps://zhuanlan.zhihu.com/p/105509080\n图中没有画出来的还有leader与follower之间的同步，这与consumer是同理的：只要follower处在ISR中，就也能够通过零拷贝机制将数据从leader所在的broker page cache传输到follower所在的broker。\n同时，page cache中的数据会随着内核中flusher线程的调度以及对sync()/fsync()的调用写回到磁盘，就算进程崩溃，也不用担心数据丢失。另外，如果consumer要消费的消息不在page cache里，才会去磁盘读取，并且会顺便预读出一些相邻的块放入page cache，以方便下一次读取。\n由此我们可以得出重要的结论：如果Kafka producer的生产速率与consumer的消费速率相差不大，那么就能几乎只靠对broker page cache的读写完成整个生产-消费过程，磁盘访问非常少。并且Kafka持久化消息到各个topic的partition文件时，是只追加的顺序写，充分利用了磁盘顺序访问快的特性，效率高。\n注意事项与相关参数 对于单纯运行Kafka的集群而言，首先要注意的就是为Kafka设置合适（不那么大）的JVM堆大小。从上面的分析可知，Kafka的性能与堆内存关系并不大，而对page cache需求巨大。根据经验值，为Kafka分配5~8GB的堆内存就已经足足够用了，将剩下的系统内存都作为page cache空间，可以最大化I/O效率。\n另一个需要特别注意的问题是lagging consumer，即那些消费速率慢、明显落后的consumer。它们要读取的数据有较大概率不在broker page cache中，因此会增加很多不必要的读盘操作。比这更坏的是，lagging consumer读取的“冷”数据仍然会进入page cache，污染了多数正常consumer要读取的“热”数据，连带着正常consumer的性能变差。在生产环境中，这个问题尤为重要。\n前面已经说过，page cache中的数据会随着内核中flusher线程的调度写回磁盘。与它相关的有以下4个参数，必要时可以调整。\n/proc/sys/vm/dirty_writeback_centisecs：flush检查的周期。单位为0.01秒，默认值500，即5秒。每次检查都会按照以下三个参数控制的逻辑来处理。\n/proc/sys/vm/dirty_expire_centisecs：如果page cache中的页被标记为dirty的时间超过了这个值，就会被直接刷到磁盘。单位为0.01秒。默认值3000，即半分钟。\n/proc/sys/vm/dirty_background_ratio：如果dirty page的总大小占空闲内存量的比例超过了该值，就会在后台调度flusher线程异步写磁盘，不会阻塞当前的write()操作。默认值为10%。\n/proc/sys/vm/dirty_ratio：如果dirty page的总大小占总内存量的比例超过了该值，就会阻塞所有进程的write()操作，并且强制每个进程将自己的文件写入磁盘。默认值为20%。\n由此可见，调整空间比较灵活的是参数2、3，而尽量不要达到参数4的阈值，代价太大了。\n我们在性能上已经做了很大的努力。 我们主要的使用场景是处理WEB活动数据，这个数据量非常大，因为每个页面都有可能大量的写入。此外我们假设每个发布 message 至少被一个consumer (通常很多个consumer) 消费， 因此我们尽可能的去降低消费的代价。\n我们还发现，从构建和运行许多相似系统的经验上来看，性能是多租户运营的关键。如果下游的基础设施服务很轻易被应用层冲击形成瓶颈，那么一些小的改变也会造成问题。通过非常快的(缓存)技术，我们能确保应用层冲击基础设施之前，将负载稳定下来。 当尝试去运行支持集中式集群上成百上千个应用程序的集中式服务时，这一点很重要，因为应用层使用方式几乎每天都会发生变化。\n我们在上一节讨论了磁盘性能。 一旦消除了磁盘访问模式不佳的情况，该类系统性能低下的主要原因就剩下了两个：大量的小型 I/O 操作，以及过多的字节拷贝。\n小型的 I/O 操作发生在客户端和服务端之间以及服务端自身的持久化操作中。\n为了避免这种情况，我们的协议是建立在一个 “消息块” 的抽象基础上，合理将消息分组。 这使得网络请求将多个消息打包成一组，而不是每次发送一条消息，从而使整组消息分担网络中往返的开销。Consumer 每次获取多个大型有序的消息块，并由服务端 依次将消息块一次加载到它的日志中。\n这个简单的优化对速度有着数量级的提升。批处理允许更大的网络数据包，更大的顺序读写磁盘操作，连续的内存块等等，所有这些都使 KafKa 将随机流消息顺序写入到磁盘， 再由 consumers 进行消费。\n另一个低效率的操作是字节拷贝，在消息量少时，这不是什么问题。但是在高负载的情况下，影响就不容忽视。为了避免这种情况，我们使用 producer ，broker 和 consumer 都共享的标准化的二进制消息格式，这样数据块不用修改就能在他们之间传递。\nbroker 维护的消息日志本身就是一个文件目录，每个文件都由一系列以相同格式写入到磁盘的消息集合组成，这种写入格式被 producer 和 consumer 共用。保持这种通用格式可以对一些很重要的操作进行优化: 持久化日志块的网络传输。 现代的unix 操作系统提供了一个高度优化的编码方式，用于将数据从 pagecache 转移到 socket 网络连接中；在 Linux 中系统调用 sendfile 做到这一点。\n为了理解 sendfile 的意义，了解数据从文件到套接字的常见数据传输路径就非常重要：\n 操作系统从磁盘读取数据到内核空间的 pagecache 应用程序读取内核空间的数据到用户空间的缓冲区 应用程序将数据(用户空间的缓冲区)写回内核空间到套接字缓冲区(内核空间) 操作系统将数据从套接字缓冲区(内核空间)复制到通过网络发送的 NIC 缓冲区 这显然是低效的，有四次 copy 操作和两次系统调用。使用 sendfile 方法，可以允许操作系统将数据从 pagecache 直接发送到网络，这样避免重新复制数据。所以这种优化方式，只需要最后一步的copy操作，将数据复制到 NIC 缓冲区。  我们期望一个普遍的应用场景，一个 topic 被多消费者消费。使用上面提交的 zero-copy（零拷贝）优化，数据在使用时只会被复制到 pagecache 中一次，节省了每次拷贝到用户空间内存中，再从用户空间进行读取的消耗。这使得消息能够以接近网络连接速度的 上限进行消费。\npagecache 和 sendfile 的组合使用意味着，在一个kafka集群中，大多数 consumer 消费时，您将看不到磁盘上的读取活动，因为数据将完全由缓存提供。\nRef https://blog.csdn.net/u013411339/article/details/99514789\nhttp://kafka.apachecn.org/documentation.html#persistence\nhttps://zhuanlan.zhihu.com/p/105509080\nhttps://shiyueqi.github.io/2017/04/27/Kafka-Pagecache%E5%8E%9F%E7%90%86/\nhttps://www.jianshu.com/p/f0b294062de8\nhttps://www.jianshu.com/p/f0b294062de8\n","href":"/kafka/kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%B9%8B%E6%80%A7%E8%83%BD%E7%AF%87/","title":"Kafka源码阅读之性能篇"},{"content":" Kafka 源码解析之 socketServer 原理篇  Kafka 是如何做到百万级高并发低延迟的?\n 原理 有别于传统的 thread per connection 模型, Kafka 使用基于 NIO 实现的 Reactor 模型.\nKafka 使用 nio 实现了自己的 socketServer 网络层代码, 而非常见的 netty、mina 框架, 从性能上来看这一块并不是主要的性能瓶颈.\nkafka socketServer 通信采取的是 NIO 的reactor模式, 是一种事件驱动模式.\n什么是 Reactor 模型  同步的等待多个事件源到达（采用select()实现）\n 将事件多路分解以及分配相应的事件服务进行处理，这个分派采用server集中处理（dispatch）\n 分解的事件以及对应的事件服务应用从分派服务中分离出去（handler）\n  为何需要 Reactor 模型  同步阻塞IO，读写阻塞，线程等待时间过长 在制定线程策略的时候，只能根据CPU的数目来限定可用线程资源，不能根据连接并发数目来制定，也就是连接有限制。否则很难保证对客户端请求的高效和公平。 多线程之间的上下文切换，造成线程使用效率并不高，并且不易扩展 状态数据以及其他需要保持一致的数据，需要采用并发同步控制  Kafka 的 socketServer 如何实现 Reactor 模型 kafka 的架构模型 工作原理： 1）先创建ServerSocketChannel对象并在Selector上注册OP_ACCEPT事件，ServerSocketChannel负责监听指定端口上的连接请求。 2）当客户端发起服务端的网络连接时，服务端的Selector监听到此OP_ACCEPT事件，会触发Acceptor来处理OP_ACCEPT。 3）当Acceptor接收到来自客户端的Socket连接请求时会为这个连接创建响应的SocketChannel，将SocketChannel设置为非阻塞模式，并在Selector上注册其关注的I/O事件，如OP_READ,OP_WRITE。此时，客户端和服务端的Socket连接建立完成。 4）当客户端通过已经建立的SocketChannel连接向服务端发送请求时，服务端的Selector会监听到OP_READ事件，并触发执行相应的处理逻辑（上图中的Reader Handler）。当服务端可以向客户端写数据时，服务端的Selector会监听到OP_WRITE事件，并触发相应的执行逻辑（上图中的Writer Handler）。 这些事情都是在同一个线程完成的，KafkaProducer中的Sender线程以及KafkaConsumer的代码都是这种设计。这样的设计时候客户端这样的并发连接数小，数据量较小的场景，这样对于服务端来说就会有缺点。如：某个请求的处理过程比较复杂会造成线程的阻塞，造成所有的后续请求读无法处理，这就会导致大量的请求超时。为了避免这种情况，就必须要求服务端在读取请求，处理请求已经发送响应等各个环节上必须能迅速的完成，这样就提升了编程的难度，在有些情况下实现不了。而且这种模式不能利用服务器多核多处理器的并行处理能力，造成资源的浪费。 为了满足高并发的需求，服务端需要使用多线程来执行逻辑。我们可以对上述架构做调整，将网络的读写的逻辑和业务处理的逻辑进行拆分，让其由不同的线程池来处理，从而实现多线程处理。 链接：https://www.jianshu.com/p/0239a3ced855\n客户端请求NIO的连接器Acceptor，同时它还具备事件的转发功能，转发到Processor处理,服务端网络事件处理器Processor 请求队列RequestChannel，存储了所有待处理的请求信息, 请求处理线程池(RequestHandlerPool)作为守护线程轮训RequestChannel的请求处理信息，并将其转发给API层对应的处理器处理API层处理器将请求处理完成之后放入到Response Queue中，并由Processor从ResponseQueue取出发送到对应的Client端.\n 1 个 Acceptor 线程，负责监听 Socket 新的连接请求，注册了 OP_ACCEPT 事件，将新的连接按照 round robin 方式交给对应的 Processor 线程处理；注意 kafka 一般情况下的 reactor 模型还是单线程Acceptor多线程handler, 每个 EndPoint (网卡) 只能构造一个 Acceptor. N 个 Processor 线程，其中每个 Processor 都有自己的 selector，它会向 Acceptor 分配的 SocketChannel 注册相应的 OP_READ 事件，N 的大小由 num.networker.threads (3) 决定； M 个 KafkaRequestHandler 线程处理请求，并将处理的结果返回给 Processor 线程对应的 response queue 中，由 Processor 将处理的结果返回给相应的请求发送者，M 的大小由 num.io.threads (8) 来决定。  整体请求流程如下:\n Acceptor 监听到来自请求者（请求者可以是来自 client，也可以来自 server）的新的连接，Acceptor 将这个请求者按照 round robin 的方式交给对对应的 Processor 进行处理； Processor 注册这个 SocketChannel 的 OP_READ 的事件，如果有请求发送过来就可以被 Processor 的 Selector 选中； Processor 将请求者发送的请求放入到一个 Request Queue 中，这是所有 Processor 共有的一个队列；queued.max.requests requestChannel 的大小, 默认500 KafkaRequestHandler 从 Request Queue 中取出请求； 调用 KafkaApis 进行相应的处理； 处理的结果放入到该 Processor 对应的 Response Queue 中（每个 request 都标识它们来自哪个 Processor），Request Queue 的数量与 Processor 的数量保持一致； Processor 从对应的 Response Queue 中取出 response； Processor 将处理的结果返回给对应的请求者  源码详解 https://www.geek-share.com/detail/2789927213.html https://www.jianshu.com/p/ff1432f5a14b\nAcceptor Acceptor是NIO里面的一个轻量级接入服务，它主要包含如下变量：\nnioSelector：Java的NIO网络选择器 serverChannel：ip和端口绑定到socket Processors:processor的容器，存放的是processor对象\n它的主要处理流程如下：\n 将nioSelector注册为OP_ACCEPT\n 轮训从nioSelector读取事件\n 通过RR的模式选择processor (Round-Robin)\n 接收一个新的链接设置(从serverSocketChannel获取socketChannel，并对它的属性进行设置)\n 移交processor的accept处理\n  Processor Processor的主要职责是将来自客户端的网络链接请求封装成RequestContext并发送给RequestChannel，同时需要对handler处理完的响应回执发送给客户端。它主要包括：\nnewConnections：是一个线程安全的队列，存放从acceptor接收到的网络新链接 inflightResponses：已发送客户端的响应，存放了和客户端的链接id(由本地ip、port以及远端ip、port还有额外一个序列值组成)和响应对象的映射 responseQueue：是一个阻塞队列，存放handler的响应请求\n它的主要处理流程如下：\n proccessor线程从newConnections中轮询获取socketChannel，并将selector监听事件修改为OP_READ；\n processNewResponses处理新的响应需求，其中类型为SendAction的就是向客户端发送响应，并将发送的响应记录在inflightResponses ,它的核心逻辑是sendResponse如下：\n Selector调用poll从客户端获取到的请求信息，并将获取到的NetworkReceive添加到completedReceives缓存中。\n 而processCompletedReceives负责处理completedReceives中的接收信息，最后封装为RequestChannel.Request，再调用requestChannel将请求添加到发送队列（即requestQueue）当中，源码逻辑如下所示：\n  RequestChannel requestChannel承载了kafka请求和响应的所有转发，它包含有如下两个变量：\nrequestQueue：是一个加锁阻塞队列，RequestChannel传输请求和响应信息的重要组件，上面讲到的RequestChannel.Request就是被放入到这个队列中\nProcessors：存储了processorid和processor的映射关系，主要是在response发送的时候从中选择对应的processor 它的两个核心功能是添加请求和发送响应回执，源码逻辑分别如下：\nSelector 的封装 (TODO) https://blog.csdn.net/zhanyuanlin/article/details/76906583 https://blog.csdn.net/zhanyuanlin/article/details/76556578 https://matt33.com/2018/06/27/kafka-server-process-model/ https://www.zhenchao.org/2019/06/21/kafka/kafka-reactor/\nRef https://www.geek-share.com/detail/2789927213.html\nReactor https://juejin.im/post/5b4570cce51d451984695a9b\n","href":"/kafka/kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%B9%8Bsocketserver%E5%8E%9F%E7%90%86%E7%AF%87/","title":"Kafka源码阅读之socketServer原理篇"},{"content":" Kafka 源码解析之 broker启动  基于 kafka 2.3.0 C:/kafka created on 0327 modified on 0410 学习了 scala 之后我又来了\n  Kafka 启动脚本分析 Kafka 核心主类 kafka.Kafka 由于作者的 java 知识相对薄弱，源码注解可能做的比较细\nobject Kafka extends Logging { // 读取配置文件方法  def getPropsFromArgs(args: Array[String]): Properties = { // 处理命令行参数的解析工具 OptionParser  val optionParser = new OptionParser(false) // 允许覆盖内容  val overrideOpt = optionParser.accepts(\u0026#34;override\u0026#34;, \u0026#34;Optional property that should override values set in server.properties file\u0026#34;) .withRequiredArg() .ofType(classOf[String]) // This is just to make the parameter show up in the help output, we are not actually using this due the  // fact that this class ignores the first parameter which is interpreted as positional and mandatory  // but would not be mandatory if --version is specified  // This is a bit of an ugly crutch till we get a chance to rework the entire command line parsing  val versionOpt = optionParser.accepts(\u0026#34;version\u0026#34;, \u0026#34;Print version information and exit.\u0026#34;) // 如果 命令行参数 为 0  if (args.length == 0 || args.contains(\u0026#34;--help\u0026#34;)) { CommandLineUtils.printUsageAndDie(optionParser, \u0026#34;USAGE: java [options] %s server.properties [--override property=value]*\u0026#34;.format(classOf[KafkaServer].getSimpleName())) } if (args.contains(\u0026#34;--version\u0026#34;)) { CommandLineUtils.printVersionAndDie() } val props = Utils.loadProps(args(0)) if (args.length \u0026gt; 1) { val options = optionParser.parse(args.slice(1, args.length): _*) if (options.nonOptionArguments().size() \u0026gt; 0) { CommandLineUtils.printUsageAndDie(optionParser, \u0026#34;Found non argument parameters: \u0026#34; + options.nonOptionArguments().toArray.mkString(\u0026#34;,\u0026#34;)) } props ++= CommandLineUtils.parseKeyValueArgs(options.valuesOf(overrideOpt).asScala) } props } // Kafka 实际的执行类  def main(args: Array[String]): Unit = { try { //上述的 getPropsFromArgs 获取配置文件信息  val serverProps = getPropsFromArgs(args) // 调用了KafkaServerStartable 对象 读取 props 文件，里面实际上是调用了 KafkaServer.startup()  val kafkaServerStartable = KafkaServerStartable.fromProps(serverProps) // 操作系统判断  try { if (!OperatingSystem.IS_WINDOWS \u0026amp;\u0026amp; !Java.isIbmJdk) new LoggingSignalHandler().register() } catch { case e: ReflectiveOperationException =\u0026gt; warn(\u0026#34;Failed to register optional signal handler that logs a message when the process is terminated \u0026#34; + s\u0026#34;by a signal. Reason for registration failure is: $e\u0026#34;, e) } // attach shutdown handler to catch terminating signals as well as normal termination  // Runtime 用了单实例的设计模式，所以在java程序中不同线程通过调用Runtime.getRuntime()获得的是同一个对象实例，  // 也就是说一个java进程中只有一个Runtime实例  //该函数的作用就是在你的程序结束前,执行一些清理工作,尤其是没有用户界面的程序.很明显,这些关闭钩子都是线程对象,  // 因此,清理工作要写在run()里.根据JDK帮助文档,清理工作不能太耗时,要尽快结束,但仍然可以对数据库进行操作.  //意思就是在jvm中增加一个关闭的钩子，当jvm关闭的时候，会执行系统中已经设置的所有通过方法addShutdownHook添加的钩子，  // 当系统执行完这些钩子后，jvm才会关闭。所以这些钩子可以在jvm关闭的时候进行内存清理、对象销毁等操作。  Runtime.getRuntime().addShutdownHook(new Thread(\u0026#34;kafka-shutdown-hook\u0026#34;) { override def run(): Unit = kafkaServerStartable.shutdown() }) // 这里终于到了 kafka 启动了， 本质上就是 KafkaServer.startup()  kafkaServerStartable.startup() // shutdown 之后需要做的一些事  kafkaServerStartable.awaitShutdown() } catch { case e: Throwable =\u0026gt; fatal(\u0026#34;Exiting Kafka due to fatal exception\u0026#34;, e) Exit.exit(1) } Exit.exit(0) } } 然后到了 kafka.server.KafkaServerStartable 和 kafka.server.KafkaServer KafkaServerStartable 包装了一层KafkaServer。本质上 KafkaServerStartable 定义了 KafkaServer 的 几种状态，将属于这几种状态的 error 抽象了出来。\n现在来看看 KafkaServer 的 startup() 启动类\nclass KafkaServer(val config: KafkaConfig, time: Time = Time.SYSTEM, threadNamePrefix: Option[String] = None, kafkaMetricsReporters: Seq[KafkaMetricsReporter] = List()) extends Logging with KafkaMetricsGroup { // 启动、是否关闭、是否启动标识  // 原子方式进行读和写的布尔值  //AtomicBoolean是Java.util.concurrent.atomic包下的原子变量，这个包里面提供了一组原子类。  // 其基本的特性就是在多线程环境下，当有多个线程同时执行这些类的实例包含的方法时，具有排他性，  // 即当某个线程进入方法，执行其中的指令时，不会被其他线程打断，而别的线程就像自旋锁一样，  // 一直等到该方法执行完成，才由JVM从等待队列中选择一个另一个线程进入，这只是一种逻辑上的理解。  // 实际上是借助硬件的相关指令来实现的，不会阻塞线程(或者说只是在硬件级别上阻塞了)。  private val startupComplete = new AtomicBoolean(false) private val isShuttingDown = new AtomicBoolean(false) private val isStartingUp = new AtomicBoolean(false) // CountDownLatch是同步工具类之一，可以指定一个计数值，在并发环境下由线程进行减1操作，  // 当计数值变为0之后，被await方法阻塞的线程将会唤醒，实现线程间的同步。  private var shutdownLatch = new CountDownLatch(1) private val jmxPrefix: String = \u0026#34;kafka.server\u0026#34; private var logContext: LogContext = null var metrics: Metrics = null val brokerState: BrokerState = new BrokerState var dataPlaneRequestProcessor: KafkaApis = null var controlPlaneRequestProcessor: KafkaApis = null var authorizer: Option[Authorizer] = None // 监听 socket 请求  var socketServer: SocketServer = null // 请求资源池  var dataPlaneRequestHandlerPool: KafkaRequestHandlerPool = null var controlPlaneRequestHandlerPool: KafkaRequestHandlerPool = null // 日志管理  var logDirFailureChannel: LogDirFailureChannel = null var logManager: LogManager = null // 分区副本管理  var replicaManager: ReplicaManager = null var adminManager: AdminManager = null var tokenManager: DelegationTokenManager = null // 动态 config 处理  var dynamicConfigHandlers: Map[String, ConfigHandler] = null var dynamicConfigManager: DynamicConfigManager = null var credentialProvider: CredentialProvider = null var tokenCache: DelegationTokenCache = null var groupCoordinator: GroupCoordinator = null var transactionCoordinator: TransactionCoordinator = null var kafkaController: KafkaController = null var kafkaScheduler: KafkaScheduler = null var metadataCache: MetadataCache = null var quotaManagers: QuotaFactory.QuotaManagers = null private var _zkClient: KafkaZkClient = null val correlationId: AtomicInteger = new AtomicInteger(0) val brokerMetaPropsFile = \u0026#34;meta.properties\u0026#34; val brokerMetadataCheckpoints = config.logDirs.map(logDir =\u0026gt; (logDir, new BrokerMetadataCheckpoint(new File(logDir + File.separator + brokerMetaPropsFile)))).toMap private var _clusterId: String = null private var _brokerTopicStats: BrokerTopicStats = null def clusterId: String = _clusterId // Visible for testing  private[kafka] def zkClient = _zkClient private[kafka] def brokerTopicStats = _brokerTopicStats newGauge( \u0026#34;BrokerState\u0026#34;, new Gauge[Int] { def value = brokerState.currentState } ) newGauge( \u0026#34;ClusterId\u0026#34;, new Gauge[String] { def value = clusterId } ) newGauge( \u0026#34;yammer-metrics-count\u0026#34;, new Gauge[Int] { def value = { com.yammer.metrics.Metrics.defaultRegistry.allMetrics.size } } ) /** * Start up API for bringing up a single instance of the Kafka server. * Instantiates the LogManager, the SocketServer and the request handlers - KafkaRequestHandlers */ // Kafka 真正 broker 的启动类  def startup() { try { info(\u0026#34;starting\u0026#34;) // 如果脚本再次在本机启动这个类，  if (isShuttingDown.get) throw new IllegalStateException(\u0026#34;Kafka server is still shutting down, cannot re-start!\u0026#34;) if (startupComplete.get) return val canStartup = isStartingUp.compareAndSet(false, true) if (canStartup) { brokerState.newState(Starting) /* setup zookeeper */ // 启动 broker 第一步就是 初始化 zk client  initZkClient(time) /* Get or create cluster_id */ // 确定 cluser id， 包装 n 层 直到配置文件 /cluster/id  _clusterId = getOrGenerateClusterId(zkClient) info(s\u0026#34;Cluster ID = $clusterId\u0026#34;) /* generate brokerId */ // 获取 broker id  val (brokerId, initialOfflineDirs) = getBrokerIdAndOfflineDirs config.brokerId = brokerId logContext = new LogContext(s\u0026#34;[KafkaServer id=${config.brokerId}] \u0026#34;) this.logIdent = logContext.logPrefix // initialize dynamic broker configs from ZooKeeper. Any updates made after this will be  // applied after DynamicConfigManager starts.  // Kafka 支持动态修改 config （都存 zk 上）  config.dynamicConfig.initialize(zkClient) /* start scheduler */ // 启动调度器 A scheduler based on java.util.concurrent.ScheduledThreadPoolExecutor  // It has a pool of kafka-scheduler- threads that do the actual work.  kafkaScheduler = new KafkaScheduler(config.backgroundThreads) kafkaScheduler.startup() /* create and configure metrics */ val reporters = new util.ArrayList[MetricsReporter] reporters.add(new JmxReporter(jmxPrefix)) val metricConfig = KafkaServer.metricConfig(config) metrics = new Metrics(metricConfig, reporters, time, true) /* register broker metrics */ _brokerTopicStats = new BrokerTopicStats quotaManagers = QuotaFactory.instantiate(config, metrics, time, threadNamePrefix.getOrElse(\u0026#34;\u0026#34;)) notifyClusterListeners(kafkaMetricsReporters ++ metrics.reporters.asScala) logDirFailureChannel = new LogDirFailureChannel(config.logDirs.size) /* start log manager */ // 启动 Log Manager  logManager = LogManager(config, initialOfflineDirs, zkClient, brokerState, kafkaScheduler, time, brokerTopicStats, logDirFailureChannel) logManager.startup() metadataCache = new MetadataCache(config.brokerId) // Enable delegation token cache for all SCRAM mechanisms to simplify dynamic update.  // This keeps the cache up-to-date if new SCRAM mechanisms are enabled dynamically.  tokenCache = new DelegationTokenCache(ScramMechanism.mechanismNames) credentialProvider = new CredentialProvider(ScramMechanism.mechanismNames, tokenCache) // Create and start the socket server acceptor threads so that the bound port is known.  // Delay starting processors until the end of the initialization sequence to ensure  // that credentials have been loaded before processing authentications.  // 启动socket server，准备对外服务了! 9092 在启动前面的内部类后 对外 服务  socketServer = new SocketServer(config, metrics, time, credentialProvider) socketServer.startup(startupProcessors = false) /* start replica manager */ // 复制管理  replicaManager = createReplicaManager(isShuttingDown) replicaManager.startup() // broker 相关信息注册到 zk 上，host:port 和防止 controller 脑裂的 epoch  // 直到这步 真正注册 到 /broker/ids 算是加入到集群中了  val brokerInfo = createBrokerInfo val brokerEpoch = zkClient.registerBroker(brokerInfo) // Now that the broker id is successfully registered, checkpoint it  checkpointBrokerId(config.brokerId) /* start token manager */ tokenManager = new DelegationTokenManager(config, tokenCache, time , zkClient) tokenManager.startup() /* start kafka controller */ // 启动kafka controller  kafkaController = new KafkaController(config, zkClient, time, metrics, brokerInfo, brokerEpoch, tokenManager, threadNamePrefix) kafkaController.startup() adminManager = new AdminManager(config, metrics, metadataCache, zkClient) /* start group coordinator */ // Hardcode Time.SYSTEM for now as some Streams tests fail otherwise, it would be good to fix the underlying issue  groupCoordinator = GroupCoordinator(config, zkClient, replicaManager, Time.SYSTEM) groupCoordinator.startup() /* start transaction coordinator, with a separate background thread scheduler for transaction expiration and log loading */ // Hardcode Time.SYSTEM for now as some Streams tests fail otherwise, it would be good to fix the underlying issue  transactionCoordinator = TransactionCoordinator(config, replicaManager, new KafkaScheduler(threads = 1, threadNamePrefix = \u0026#34;transaction-log-manager-\u0026#34;), zkClient, metrics, metadataCache, Time.SYSTEM) transactionCoordinator.startup() /* Get the authorizer and initialize it if one is specified.*/ authorizer = Option(config.authorizerClassName).filter(_.nonEmpty).map { authorizerClassName =\u0026gt; val authZ = CoreUtils.createObject[Authorizer](authorizerClassName) authZ.configure(config.originals()) authZ } val fetchManager = new FetchManager(Time.SYSTEM, new FetchSessionCache(config.maxIncrementalFetchSessionCacheSlots, KafkaServer.MIN_INCREMENTAL_FETCH_SESSION_EVICTION_MS)) /* start processing requests */ // 从这里开始， 准备 完成， 开始处理外界消息。  dataPlaneRequestProcessor = new KafkaApis(socketServer.dataPlaneRequestChannel, replicaManager, adminManager, groupCoordinator, transactionCoordinator, kafkaController, zkClient, config.brokerId, config, metadataCache, metrics, authorizer, quotaManagers, fetchManager, brokerTopicStats, clusterId, time, tokenManager) // 起线程池，传入 socket server 对象  dataPlaneRequestHandlerPool = new KafkaRequestHandlerPool(config.brokerId, socketServer.dataPlaneRequestChannel, dataPlaneRequestProcessor, time, config.numIoThreads, s\u0026#34;${SocketServer.DataPlaneMetricPrefix}RequestHandlerAvgIdlePercent\u0026#34;, SocketServer.DataPlaneThreadPrefix) socketServer.controlPlaneRequestChannelOpt.foreach { controlPlaneRequestChannel =\u0026gt; controlPlaneRequestProcessor = new KafkaApis(controlPlaneRequestChannel, replicaManager, adminManager, groupCoordinator, transactionCoordinator, kafkaController, zkClient, config.brokerId, config, metadataCache, metrics, authorizer, quotaManagers, fetchManager, brokerTopicStats, clusterId, time, tokenManager) controlPlaneRequestHandlerPool = new KafkaRequestHandlerPool(config.brokerId, socketServer.controlPlaneRequestChannelOpt.get, controlPlaneRequestProcessor, time, 1, s\u0026#34;${SocketServer.ControlPlaneMetricPrefix}RequestHandlerAvgIdlePercent\u0026#34;, SocketServer.ControlPlaneThreadPrefix) } // 监控相关  Mx4jLoader.maybeLoad() /* Add all reconfigurables for config change notification before starting config handlers */ config.dynamicConfig.addReconfigurables(this) /* start dynamic config manager */ dynamicConfigHandlers = Map[String, ConfigHandler](ConfigType.Topic -\u0026gt; new TopicConfigHandler(logManager, config, quotaManagers, kafkaController), ConfigType.Client -\u0026gt; new ClientIdConfigHandler(quotaManagers), ConfigType.User -\u0026gt; new UserConfigHandler(quotaManagers, credentialProvider), ConfigType.Broker -\u0026gt; new BrokerConfigHandler(config, quotaManagers)) // Create the config manager. start listening to notifications  dynamicConfigManager = new DynamicConfigManager(zkClient, dynamicConfigHandlers) dynamicConfigManager.startup() // socket server 开始对外服务  socketServer.startDataPlaneProcessors() socketServer.startControlPlaneProcessor() brokerState.newState(RunningAsBroker) // 修改初始 new KafkaServer 类的状态，启动完成  shutdownLatch = new CountDownLatch(1) startupComplete.set(true) isStartingUp.set(false) AppInfoParser.registerAppInfo(jmxPrefix, config.brokerId.toString, metrics, time.milliseconds()) info(\u0026#34;started\u0026#34;) } } catch { case e: Throwable =\u0026gt; fatal(\u0026#34;Fatal error during KafkaServer startup. Prepare to shutdown\u0026#34;, e) isStartingUp.set(false) shutdown() throw e } } 核心 经过以上分析，kafka 大致的启动流程我们就知道了，接下来是看 kafka 内部 各个 startup 出来的模块，到底每个是负责什么的。\n比方说: KafkaScheduler是一个基于java.util.concurrent.ScheduledThreadPoolExecutor的调度器，它内部是以前缀kafka-scheduler-xx（xx是线程序列号）的线程池处理真正的工作。\n","href":"/kafka/kafka%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E4%B9%8Bbroker%E5%90%AF%E5%8A%A8/","title":"Kafka源码阅读之broker启动"},{"content":" Kafka 源码阅读 这里是一些kafka源码阅读笔记\n","href":"/kafka/intro/","title":"Intro"},{"content":"","href":"/authors/","title":"Authors"},{"content":"","href":"/categories/","title":"Categories"},{"content":"","href":"/tags/github/","title":"github"},{"content":" How to hugo 日常使用篇  本篇介绍如何发布一篇文章并编写shell脚本快捷发布/\n  How to hugo 日常使用篇  本地撰写博文 发布 shell 脚本自动发布 TODO Ref    本篇文章介绍如何发布一篇文章并上传到网页端. 一共只有两个步骤\n 本地撰写博文 cd ./mytopia hugo server -D // 此时开启的是fast render 模式, 会热更新你的博文编辑. hugo new /posts/new_intro.md // 创建一篇新的博文 发布 cd ./mytopia hugo -D // 默认hugo new出来的文章都有个标签是草稿, -D 指的是build 所有草稿 cd build git add . git commit -m \u0026#34;xxx\u0026#34; git push original master 注意, 以上这部分推送之后, 页面就更新了, 但是其实本体文件并没有上传到github保存, 建议先如下操作:\ncd ./mytopia hugo -D git add . git commit -m \u0026#34;xxx\u0026#34; git push original master 由于每次想写文章都要敲以上那么多条命令, 当然我们还是写一个shell脚本更加方便.\nshell 脚本自动发布 deploy.sh 使用方法:\n 复制如下脚本并chomd + x deploy.sh 自动commit ./deploy.sh 自动push 到github并更新page, 或者./deploy.sh + xxx\n#!/bin/sh  # If a command fails then the deploy stops set -e printf \u0026#34;\\033[0;32mDeploying updates to tangzhongham...\\033[0m\\n\u0026#34; # Build the project. hugo -D # if using a theme, replace with `hugo -t \u0026lt;YOURTHEME\u0026gt;` # push your files to github msg=\u0026#34;saving file and rebuilding site $(date)\u0026#34; if [ -n \u0026#34;$*\u0026#34; ]; then msg=\u0026#34;$*\u0026#34; fi git add . git commit -m \u0026#34;$msg\u0026#34; # Push source and build repos. git push origin master # Go To Public folder cd public # Add changes to git. git add . # Commit changes. git commit -m \u0026#34;$msg\u0026#34; # Push source and build repos. git push origin master printf \u0026#34;upload success, enjoy your journey! \u0026#34;  TODO deployment 文件撰写  创建了一个改版的sh文件,不知道咋样,试试.\nsearch 功能暂时去掉  一个很坑的事情, 按照文档添加 search 则会把homepage的介绍挤掉. 放到sidebar 则无法使用\u0026hellip; 暂时去掉搜索吧.\nRef minimo模版\nhugo官方部署文档\n","href":"/intro/how_to_hugo%E6%97%A5%E5%B8%B8%E4%BD%BF%E7%94%A8%E7%AF%87/","title":"How_to_hugo日常使用篇"},{"content":"","href":"/tags/hugo/","title":"hugo"},{"content":"","href":"/intro/","title":"Intros"},{"content":"","href":"/tags/markdown/","title":"markdown"},{"content":"","href":"/tags/","title":"Tags"},{"content":"","href":"/categories/tutorial/","title":"tutorial"},{"content":"","href":"/authors/tzh/","title":"tzh"},{"content":" How to hugo 安装篇  本篇介绍如何安装 hugo 并将 blog 部署到 github pages.\n ","href":"/intro/how_to_hugo%E5%AE%89%E8%A3%85%E7%AF%87/","title":"How_to_hugo安装篇"},{"content":" hugo 日志操作流程 [toc]\n 本篇文章介绍如何发布一篇文章并上传到网页端. 一共只有两个步骤\n 本地撰写博文 cd ./mytopia hugo server -D // 此时开启的是fast render 模式, 会热更新你的博文编辑. hugo new /posts/new_intro.md // 创建一篇新的博文 发布 cd ./mytopia hugo -D cd build git add . git commit -m \u0026#34;xxx\u0026#34; git push original master 注意, 以上这部分推送之后, 页面就更新了, 但是其实本体文件并没有上传到github保存, 建议先如下操作:\ncd ./mytopia hugo -D git add . git commit -m \u0026#34;xxx\u0026#34; git push original master 二进制图片怎么办: TODO deployment 文件撰写  创建了一个改版的sh文件,不知道咋样,试试.\n一个很坑的事情, 按照文档添加 search 则会把homepage的介绍挤掉. 放到sidebar 则无法使用\u0026hellip; 暂时去掉搜索吧.\n文本 #!/bin/sh  # If a command fails then the deploy stops set -e printf \u0026#34;\\033[0;32mDeploying updates to tangzhongham...\\033[0m\\n\u0026#34; # Build the project. hugo -D # if using a theme, replace with `hugo -t \u0026lt;YOURTHEME\u0026gt;` # push your files to github msg=\u0026#34;saving file and rebuilding site $(date)\u0026#34; if [ -n \u0026#34;$*\u0026#34; ]; then msg=\u0026#34;$*\u0026#34; fi git add . git commit -m \u0026#34;$msg\u0026#34; # Push source and build repos. git push origin master # Go To Public folder cd public # Add changes to git. git add . # Commit changes. git commit -m \u0026#34;$msg\u0026#34; # Push source and build repos. git push origin master printf \u0026#34;upload success, enjoy your journey! \u0026#34; ps: 发现该shell脚本自带传参功能了...","href":"/posts/new_intro/","title":"New_intro"},{"content":"","href":"/posts/","title":"Posts"},{"content":" Hello! 有问题欢迎交流!\n微信: tzh-1166\n邮箱: 13122260573@163.com\n","href":"/about/","title":""},{"content":"","href":"/intro/how_to_hugo/","title":"How_to_hugo"},{"content":" 2019 年 11 月  2019 年 11 月  1119 - 1126 11 19 周二  Thoughts TODO LIST     This is for PRIVATE ONLY !!!\n 1119 - 1126 11 19 周二 Thoughts 今天终于把页面部署好了~ 然后可以舒舒服服的发布,然后在哪里都能看啦.\nTODO LIST deploy 脚本研究 git submodule 是什么意思 文章润色~ 明天要开始输出 kafka 的东西啦~ 然后 Spark 源码也要看起来了!!!  ","href":"/diary/201911/","title":"201911"},{"content":"","href":"/tags/create/","title":"create"},{"content":"","href":"/diary/","title":"Diaries"},{"content":"","href":"/categories/diary/","title":"diary"},{"content":"","href":"/tags/diary/","title":"diary"},{"content":"","href":"/tags/orz.../","title":"ORZ..."},{"content":" How to deploy your hugo sites to Github Pages  How to deploy your hugo sites to Github Pages  部署到 Github 个人页面 常见错误 TODO LIST   部署到 Github 个人页面  在github 分别建立 mytopia 和 \u0026lt;username\u0026gt;.github.io 的仓库，前者用来存放网页的源文件，后者用来存放最终展示的网站内容\n 进入之前教程中的本地目录\ncd /mytopia 将 mytopia 项目关联到远程的 mytopia 仓库\ngit remote add origin git@github.com/TangZhongham/mytopia.git 将本地网站全部推送到远程的 mytopia 仓库\ngit push -u origin master  可能会出现push 不了的原因。可能需要你 git add .然后git commit -m \u0026quot;first commit\u0026quot;\n前文要注意git submodule 和 git init，所以这边才不用git init了。src refspec master does not match 错误是由于没有 add 东西就 push 了。\n 此时所有代码已经被推送到 github 上了。\n 确保服务正常，并确保根目录下没有 /public文件夹。\nrm -r /public 关闭hugo服务器ctrl+C，执行以下命令创建 public 子模块，将用于github page 展示。\ngit submodule add -b master https://github.com/TangZhongham/tangzhongham.github.io.git public 执行hugo命令，自动创建 public 文件夹。然后将代码提交到远程 mytopia 仓库\nhugo cd public git status git add . git commit -m \u0026#34;first commit\u0026#34; git push -u origin master  不行，重新rm -r public 试试。tangzhongham.github.io 建点东西，好像听说不能完全为空。\n删完又 git add git commit/ git push -u origin master 了一波。\n重复第7步\ncd ./public git pull --allow-unrelated-histories git push 解决两边不一样的问题（http那边创建了个README）  现在的操作流程就是说，先改文章。然后 /mytopia 下面 hugo -buildDrafts 然后 git add/commit/push 三连，之后 去 /build 里面 三连，页面才能更新。 (发现不成功的原因是 -buildDrafts 少了一个 - 符号, 要么是-D 要么是 \u0026ndash;buildDrafts)\n现在他妈js 又404 了，搞毛线 新问题好像是在外面 git push 之后，里面再 git status 就 检测不到了，然后页面上 mytopia 的 public 被 push 了，但是 io 的没有。 不知道404 是不是由于这个原因。尝试 hugo -buildDrafts 之后先提交里面的试试。\n常见错误 TODO LIST 预备流程：go/git/hugo 分两篇，怎样本地启动，怎样部署。注意事项（http 空文件问题） 可以重新部署一次玩（好累，往后稍稍吧) Git submodule 的使用，为啥两边要更新两次 deploy 脚本的编写 Enjoy！  ","href":"/intro/how_to_github_pages/","title":"How_to_github_pages"},{"content":" How to Hugo [toc]\n安装篇 Git 安装 略\nHugo 安装 Windows 下载二进制文件: Windows 安装其实要比 Mac 舒服一些.找到 binary 二进制文件 的Releases, 下载下来安装就行. 下载链接\n添加到Path: 不会的可以谷歌.\nMac 诚然, 我一开始当然是愉快的使用 brew install hugo 的方式. 问题来了\u0026hellip;由于方方面的原因,这样下载的 hugo 版本太低了,和我喜欢的主题有冲突, 所以 mac 也老老实实和 win 一样找二进制安装然后配置path 吧~\n ps: Mac 软链接有点小坑, 没搞定的谷歌可以解决.\n 启动篇  Hugo 是目前最舒服的markdown 静态网站方案了. 简单五步开始搭建博客吧.\n 第一步: 网站 由于静态网站的便捷性, hugo 建立一个网站只需要一条命令.\nhugo new site mytopiia 此时 hugo 生成的目录结构如下: mytopiia ├── archetypes # 存放生成博客的模版 │ └── default.md ├── config.toml # tommy 的改良版 yaml ├── content # 你写markdown 的地方 ├── data # Hugo 处理的数据 ├── layouts # 布局文件 ├── static # 静态文件 └── themes # 主题 严格意义上来说, 这一步已经可以部署你的“网站”了. 先挑一个主题吧.\n第二步: 主题 选好主题后, 这里涉及到一些 git 的知识, 先照着敲就对了.\ncd mytopiia # 下载你喜欢的 theme, 下面是我喜欢的. git init git submodule add https://github.com/panr/hugo-theme-terminal.git themes/terminal # 把主题名称添加到 config 里生效. echo \u0026#39;theme = \u0026#34;terminal\u0026#34;\u0026#39; \u0026gt;\u0026gt; config.toml 第三步: Config 第四步: Markdown m\n第五步: Server 润色篇 ","href":"/intro/how_to_hugo_1/","title":"How_to_hugo_1"},{"content":" All cowardice comes from not loving or not loving well, which is the same thing.\n ","href":"/","title":""},{"content":" 1. Markdown 5分钟使用指南  注意: 该主题的toc渲染有点问题,不支持1.1.1 这种表达(和 visual studio code 里面冲突)   1. Markdown 5分钟使用指南  1.1. Why Markdown How to Markdown 1.2.1. 结构 1.2.2. 段落  1.2.2.1. 分隔符 1.2.2.2. 引用 1.2.2.3. 代码块 1.2.2.3.1. 单行代码 1.2.2.3.2. 多行代码  1.2.3. 句子  1.2.3.1. 换行 1.2.3.2. Bullet Dot  1.2.4. 文本  1.2.4.1. 链接  1.3. Others 1.3.1. 杂   1.1. Why Markdown  Markdown is a lightweight markup language that you can use to add formatting elements to plaintext text documents.\n Markdown 本质上就是一种标记语言，让你在不需要过度关注文章结构的同时，提供了符合逻辑的文章结构。\nHow to Markdown 正如以上所说，Markdown 只是为了让你更舒服的组织好文章架构，那么从以下几个方面来使用则很符合逻辑。\n1.2.1. 结构 Markdown 把一篇文章分为如下结构:\n一级标题只能有一个，等价于文章的标题，所有其他等级标题都在一级标题下面。\n1.2.2. 段落 正文直接手写就行。\n1.2.2.1. 分隔符 如下：\n1.2.2.2. 引用  这样就可以引用别人的话。\n 引用功能可以嵌套。\n 哈哈\n   1.2.2.3. 代码块 1.2.2.3.1. 单行代码 单行代码可以这么写：def\n1.2.2.3.2. 多行代码 多行代码一样的，同时在后接 python 等可以支持不同语法的代码高亮。\ndef hello_world(): \u0026#34;\u0026#34;\u0026#34; 代码里面就一样的 \u0026#34;\u0026#34;\u0026#34; pass 1.2.3. 句子 1.2.3.1. 换行 Markdown 的换行有点傻逼。 可以这么换(貌似没有更好的解决办法)\n1.2.3.2. Bullet Dot 这样就行 会自动往后添加，不用每个都手打，放心。  1.2.4. 文本 文本的内容就比较有趣了。 比方说可以加粗，可以划去内容，可以 斜体字 ，也可以下划线。\n1.2.4.1. 链接 可以直接这样\n图片的话： 1.3. Others 1.3.1. 杂 ","href":"/posts/how_to_hugo/","title":"How_to_hugo"},{"content":" Markdown 5分钟使用指南  Markdown 5分钟使用指南  Why Markdown How to Markdown 结构 段落  分隔符 引用 代码块 单行代码 多行代码  句子  换行 Bullet Dot  文本  链接  Others 杂   Why Markdown  Markdown is a lightweight markup language that you can use to add formatting elements to plaintext text documents.\n Markdown 本质上就是一种标记语言，让你在不需要过度关注文章结构的同时，提供了符合逻辑的文章结构。\nHow to Markdown 正如以上所说，Markdown 只是为了让你更舒服的组织好文章架构，那么从以下几个方面来使用则很符合逻辑。\n结构 Markdown 把一篇文章分为如下结构:\n 这是一级标题 这是二级标题 这是三级标题 这是四级标题 这是五级标题  一级标题只能有一个，等价于文章的标题，所有其他等级标题都在一级标题下面。\n段落 正文直接手写就行。\n分隔符 如下：\n引用  这样就可以引用别人的话。\n 引用功能可以嵌套。\n 哈哈\n   代码块 单行代码 单行代码可以这么写：def\n多行代码 多行代码一样的，同时在后接 python 等可以支持不同语法的代码高亮。\ndef hello_world(): \u0026#34;\u0026#34;\u0026#34; 代码里面就一样的 \u0026#34;\u0026#34;\u0026#34; pass 句子 换行 Markdown 的换行有点傻逼。 可以这么换(貌似没有更好的解决办法)\nBullet Dot 这样就行 会自动往后添加，不用每个都手打，放心。  文本 文本的内容就比较有趣了。 比方说可以加粗，可以划去内容，可以 斜体字 ，也可以下划线。\n链接 可以直接这样\nhttp://www.hao123.com\n图片的话： Others 杂 ","href":"/posts/how_to_markdown/","title":"How_to_markdown"},{"content":"","href":"/categories/posts/","title":"posts"},{"content":"","href":"/page/search/","title":""},{"content":"","href":"/page/","title":"Pages"},{"content":"","href":"/series/","title":"Series"}]
